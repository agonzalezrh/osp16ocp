- block:
  - name: fix grub entries to have name start with GRUB_
    replace:
      path: /etc/default/grub
      regexp: ^(TRIPLEO_HEAT_TEMPLATE_KERNEL_ARGS)(.*)
      replace: GRUB_\1\2
  - name: fix grub entries in append statement
    replace:
      path: /etc/default/grub
      regexp: (.*){(TRIPLEO_HEAT_TEMPLATE_KERNEL_ARGS)}(.*)
      replace: \1{GRUB_\2}\3
  name: upgrade prepare for leapp to align kernel arg shortcommings in leapp
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  when:
  - step|int == 3
  - upgrade_leapp_enabled
- name: Gather missing facts
  setup:
    gather_subset: distribution
  tags:
  - never
  - nova_hybrid_state
  when: ansible_facts['distribution'] is not defined or ansible_facts['distribution_major_version']
    is not defined
- block:
  - failed_when: false
    name: Check if iscsid is running with proper image
    register: hybrid_iscsid
    shell: 'docker ps | grep "{{iscsid_image}}"

      '
  - block:
    - name: Update the iscsid paunch image in config
      shell: 'set -o pipefail

        jq ''.iscsid.image = "{{ iscsid_image }}" | {"iscsid": .iscsid }'' \

        /var/lib/tripleo-config/docker-container-startup-config-step_3.json >\

        /var/lib/tripleo-config/docker-container-hybrid_iscsid.json

        '
    - lineinfile:
        dest: /etc/hosts
        line: '{{ undercloud_hosts_entries | join('''') }}'
        state: present
      name: Make sure the Undercloud hostname is included in /etc/hosts
      when:
      - undercloud_hosts_entries is defined
    - name: Set container_registry_insecure_registries fact.
      set_fact:
        container_registry_insecure_registries: []
    - ini_file:
        option: registries
        path: /etc/containers/registries.conf
        section: registries.insecure
        value: '{{ container_registry_insecure_registries }}'
      name: Set container_registry_insecure registries
      register: ini_read_result
      when: container_registry_insecure_registries != []
    - args:
        executable: /usr/bin/bash
      name: Restart docker and apply the paunch config
      shell: "set -o pipefail\n# Get list of running containers\nRUNNING=\"$( docker\
        \ ps --format '{{ '{{' }}.Names{{ '}}' }}' )\"\n# Restart docker\nsystemctl\
        \ restart docker\n# Compare running containers now vs before\nTO_STOP=\"$(grep\
        \ -v -f <(echo \"${RUNNING}\")  <(docker ps --format '{{ '{{' }}.Names{{ '}}'\
        \ }}'))\"\n# Check if we need to stop anything and stop it\nif [ -n \"${TO_STOP}\"\
        \ ]; then\n  echo \"${TO_STOP}\" | xargs -r docker stop\nfi\n"
      when:
      - container_registry_insecure_registries != []
      - ini_read_result is changed
    - docker_container:
        name: iscsid
        state: absent
      name: Remove iscsid container before applying new paunch config
    - name: Apply paunch config for iscsid
      shell: paunch apply --file /var/lib/tripleo-config/docker-container-hybrid_iscsid.json
        --config-id hybrid_iscsid
    name: Implement the hybrid state (only if the compute is still Queens)
    when: hybrid_iscsid.rc != 0
  name: Switch iscsid to hybrid state
  tags:
  - never
  - nova_hybrid_state
  vars:
    iscsid_image: registry.redhat.io/rhosp-rhel8/openstack-iscsid:16.2
  when:
  - step|int == 0
  - ansible_facts['distribution'] == 'RedHat'
  - ansible_facts['distribution_major_version'] is version('7', '==')
- block:
  - failed_when: false
    name: Check if nova_compute is running with proper image
    register: hybrid_nova_compute
    shell: 'docker ps | grep "{{nova_compute_image}}"

      '
  - block:
    - name: Update the nova_compute paunch image in config
      shell: 'set -o pipefail

        jq ''.nova_compute.image = "{{ nova_compute_image }}" | {"nova_compute": .nova_compute
        }'' \

        /var/lib/tripleo-config/docker-container-startup-config-step_4.json >\

        /var/lib/tripleo-config/docker-container-hybrid_nova_compute.json

        '
    - ini_file:
        path: /var/lib/config-data/puppet-generated/nova_libvirt/etc/nova/nova.conf
        section: database
        state: absent
      name: Remove database section from nova_compute config
    - ini_file:
        path: /var/lib/config-data/puppet-generated/nova_libvirt/etc/nova/nova.conf
        section: api_database
        state: absent
      name: Remove api_database section from nova_compute config
    - name: is Instance HA enabled
      set_fact:
        instance_ha_enabled: false
    - block:
      - file:
          path: /var/lib/nova/instanceha
          state: directory
        name: prepare Instance HA script directory
      - copy:
          content: "#!/usr/libexec/platform-python\n\nimport os\nimport sys\nimport\
            \ time\nimport inspect\nimport logging\nimport argparse\nimport oslo_config.cfg\n\
            import requests.exceptions\n\ndef is_forced_down(connection, hostname):\n\
            \    services = connection.services.list(host=hostname, binary=\"nova-compute\"\
            )\n    for service in services:\n        if service.forced_down:\n   \
            \         return True\n    return False\n\ndef evacuations_done(connection,\
            \ hostname):\n    # Get a list of migrations.\n    #  :param host: (optional)\
            \ filter migrations by host name.\n    #  :param status: (optional) filter\
            \ migrations by status.\n    #  :param cell_name: (optional) filter migrations\
            \ for a cell.\n    #\n    migrations = connection.migrations.list(host=hostname)\n\
            \n    print(\"Checking %d migrations\" % len(migrations))\n    for migration\
            \ in migrations:\n        # print migration.to_dict()\n        #\n   \
            \     # {\n        # u'status': u'error',\n        # u'dest_host': None,\n\
            \        # u'new_instance_type_id': 2,\n        # u'old_instance_type_id':\
            \ 2,\n        # u'updated_at': u'2018-04-22T20:55:29.000000',\n      \
            \  # u'dest_compute':\n        #   u'overcloud-novacompute-2.localdomain',\n\
            \        # u'migration_type': u'live-migration',\n        # u'source_node':\n\
            \        #   u'overcloud-novacompute-0.localdomain',\n        # u'id':\
            \ 8,\n        # u'created_at': u'2018-04-22T20:52:58.000000',\n      \
            \  # u'instance_uuid':\n        #   u'd1c82ce8-3dc5-48db-b59f-854b3b984ef1',\n\
            \        # u'dest_node':\n        #   u'overcloud-novacompute-2.localdomain',\n\
            \        # u'source_compute':\n        #   u'overcloud-novacompute-0.localdomain'\n\
            \        # }\n        # Acceptable: done, completed, failed\n        if\
            \ migration.status in [\"running\", \"accepted\", \"pre-migrating\"]:\n\
            \            return False\n    return True\n\ndef safe_to_start(connection,\
            \ hostname):\n    if is_forced_down(connection, hostname):\n        print(\"\
            Waiting for fence-down flag to be cleared\")\n        return False\n \
            \   if not evacuations_done(connection, hostname):\n        print(\"Waiting\
            \ for evacuations to complete or fail\")\n        return False\n    return\
            \ True\n\ndef create_nova_connection(options):\n    try:\n        from\
            \ novaclient import client\n        from novaclient.exceptions import\
            \ NotAcceptable\n    except ImportError:\n        print(\"Nova not found\
            \ or not accessible\")\n        sys.exit(1)\n\n    from keystoneauth1\
            \ import loading\n    from keystoneauth1 import session\n    from keystoneclient\
            \ import discover\n\n    # Prefer the oldest and strip the leading 'v'\n\
            \    keystone_versions = discover.available_versions(options[\"auth_url\"\
            ][0])\n    keystone_version = keystone_versions[0]['id'][1:]\n    kwargs\
            \ = dict(\n        auth_url=options[\"auth_url\"][0],\n        username=options[\"\
            username\"][0],\n        password=options[\"password\"][0]\n        )\n\
            \n    if discover.version_match(\"2\", keystone_version):\n        kwargs[\"\
            tenant_name\"] = options[\"tenant_name\"][0]\n\n    elif discover.version_match(\"\
            3\", keystone_version):\n        kwargs[\"project_name\"] = options[\"\
            project_name\"][0]\n        kwargs[\"user_domain_name\"] = options[\"\
            user_domain_name\"][0]\n        kwargs[\"project_domain_name\"] = options[\"\
            project_domain_name\"][0]\n\n    loader = loading.get_plugin_loader('password')\n\
            \    keystone_auth = loader.load_from_options(**kwargs)\n    keystone_session\
            \ = session.Session(auth=keystone_auth, verify=(not options[\"insecure\"\
            ]))\n\n    nova_endpoint_type = 'internalURL'\n    # We default to internalURL\
            \ but we allow this to be overridden via\n    # the [placement]/os_interface\
            \ key.\n    if 'os_interface' in options and len(options[\"os_interface\"\
            ]) == 1:\n        nova_endpoint_type = options[\"os_interface\"][0]\n\
            \    # Via https://review.opendev.org/#/c/492247/ os_interface has been\
            \ deprecatd in queens\n    # and we need to use 'valid_interfaces' which\
            \ is a:\n    # \"List of interfaces, in order of preference, for endpoint\
            \ URL. (list value)\"\n    # Since it is not explicitely set in nova.conf\
            \ we still keep the check for os_interface\n    elif 'valid_interfaces'\
            \ in options and len(options[\"valid_interfaces\"]) >= 1:\n        nova_endpoint_type\
            \ = options[\"valid_interfaces\"][0]\n\n    # This mimicks the code in\
            \ novaclient/shell.py\n    if nova_endpoint_type in ['internal', 'public',\
            \ 'admin']:\n        nova_endpoint_type += 'URL'\n\n    if 'region_name'\
            \ in options:\n        region = options['region_name'][0]\n    elif 'os_region_name'\
            \ in options:\n        region = options['os_region_name'][0]\n    else:\
            \ # We actually try to make a client call even with an empty region\n\
            \        region = None\n    nova_versions = [ \"2.23\", \"2\" ]\n    for\
            \ version in nova_versions:\n        clientargs = inspect.getargspec(client.Client).varargs\n\
            \        # Some versions of Openstack prior to Ocata only\n        # supported\
            \ positional arguments for username,\n        # password, and tenant.\n\
            \        #\n        # Versions since Ocata only support named arguments.\n\
            \        #\n        # So we need to use introspection to figure out how\
            \ to\n        # create a Nova client.\n        #\n        # Happy days\n\
            \        #\n        if clientargs:\n            # OSP < Ocata\n      \
            \      # ArgSpec(args=['version', 'username', 'password', 'project_id',\
            \ 'auth_url'],\n            #         varargs=None,\n            #   \
            \      keywords='kwargs', defaults=(None, None, None, None))\n       \
            \     nova = client.Client(version,\n                                \
            \ None, # User\n                                 None, # Password\n  \
            \                               None, # Tenant\n                     \
            \            None, # Auth URL\n                                 insecure=options[\"\
            insecure\"],\n                                 region_name=region,\n \
            \                                session=keystone_session, auth=keystone_auth,\n\
            \                                 http_log_debug=\"verbose\" in options,\n\
            \                                 endpoint_type=nova_endpoint_type)\n\
            \        else:\n            # OSP >= Ocata\n            # ArgSpec(args=['version'],\
            \ varargs='args', keywords='kwargs', defaults=None)\n            nova\
            \ = client.Client(version,\n                                 region_name=region,\n\
            \                                 session=keystone_session, auth=keystone_auth,\n\
            \                                 http_log_debug=\"verbose\" in options,\n\
            \                                 endpoint_type=nova_endpoint_type)\n\n\
            \        try:\n            nova.hypervisors.list()\n            return\
            \ nova\n\n        except NotAcceptable as e:\n            logging.warning(e)\n\
            \n        except Exception as e:\n            logging.warning(\"Nova connection\
            \ failed. %s: %s\" % (e.__class__.__name__, e))\n\n    print(\"Couldn't\
            \ obtain a supported connection to nova, tried: %s\\n\" % repr(nova_versions))\n\
            \    return None\n\n\nparser = argparse.ArgumentParser(description='Process\
            \ some integers.')\nparser.add_argument('--config-file', dest='nova_config',\
            \ action='store',\n                    default=\"/etc/nova/nova.conf\"\
            ,\n                    help='path to nova configuration (default: /etc/nova/nova.conf)')\n\
            parser.add_argument('--nova-binary', dest='nova_binary', action='store',\n\
            \                    default=\"/usr/bin/nova-compute\",\n            \
            \        help='path to nova compute binary (default: /usr/bin/nova-compute)')\n\
            parser.add_argument('--enable-file', dest='enable_file', action='store',\n\
            \                    default=\"/var/lib/nova/instanceha/enabled\",\n \
            \                   help='file exists if instance HA is enabled on this\
            \ host '\\\n                    '(default: /var/lib/nova/instanceha/enabled)')\n\
            \n\nsections = {}\n(args, remaining) = parser.parse_known_args(sys.argv)\n\
            \nconfig = oslo_config.cfg.ConfigParser(args.nova_config, sections)\n\
            config.parse()\nconfig.sections[\"placement\"][\"insecure\"] = 0\nconfig.sections[\"\
            placement\"][\"verbose\"] = 1\n\nif os.path.isfile(args.enable_file):\n\
            \    connection = None\n    while not connection:\n        # Loop in case\
            \ the control plane is recovering when we run\n        connection = create_nova_connection(config.sections[\"\
            placement\"])\n        if not connection:\n            time.sleep(10)\n\
            \n    while not safe_to_start(connection, config.sections[\"DEFAULT\"\
            ][\"host\"][0]):\n        time.sleep(10)\n\nreal_args = [args.nova_binary,\
            \ '--config-file', args.nova_config]\nreal_args.extend(remaining[1:])\n\
            os.execv(args.nova_binary, real_args)\n"
          dest: /var/lib/nova/instanceha/check-run-nova-compute
          mode: 493
        name: install Instance HA script that runs nova-compute
      name: install Instance HA recovery script
      when: instance_ha_enabled|bool
    - lineinfile:
        dest: /etc/hosts
        line: '{{ undercloud_hosts_entries | join('''') }}'
        state: present
      name: Make sure the Undercloud hostname is included in /etc/hosts
      when:
      - undercloud_hosts_entries is defined
    - name: Set container_registry_insecure_registries fact.
      set_fact:
        container_registry_insecure_registries: []
    - ini_file:
        option: registries
        path: /etc/containers/registries.conf
        section: registries.insecure
        value: '{{ container_registry_insecure_registries }}'
      name: Set container_registry_insecure registries
      register: ini_read_result
      when: container_registry_insecure_registries != []
    - name: Restart docker
      service:
        name: docker
        state: restarted
      when:
      - container_registry_insecure_registries != []
      - ini_read_result is changed
    - docker_container:
        name: nova_compute
        state: absent
      name: Remove nova_compute container before applying new paunch config
    - name: Apply paunch config for nova_compute
      shell: 'paunch apply --file /var/lib/tripleo-config/docker-container-hybrid_nova_compute.json
        --config-id hybrid_nova_compute

        '
    name: Implement the hybrid state (only if the compute is still Queens)
    when: hybrid_nova_compute.rc != 0
  name: Switch compute to hybrid state
  tags:
  - never
  - nova_hybrid_state
  vars:
    nova_compute_image: registry.redhat.io/rhosp-rhel8/openstack-nova-compute:16.2
  when:
  - step|int == 0
  - ansible_facts['distribution'] == 'RedHat'
  - ansible_facts['distribution_major_version'] is version('7', '==')
- failed_when: false
  name: Remove openstack-nova-compute and python-nova package during upgrade
  package:
    name:
    - openstack-nova-compute
    - python-nova
    state: removed
  when: step|int == 2
- file:
    path: /etc/cron.daily/containers-tmpwatch
    state: absent
  name: Ensure old cron.daily is absent
  when: step|int == 1
- block:
  - args:
      executable: /bin/bash
      warn: false
    changed_when: _selinux_config_data.rc == 2
    failed_when: _selinux_config_data.rc not in [0,2]
    name: Ensure /var/lib/config-data context
    register: _selinux_config_data
    shell: "set -o pipefail\nif [[ -e /var/lib/config-data ]]; then\n  chcon -R -t\
      \ container_file_t /var/lib/config-data\n  exit 2\nfi"
  - lineinfile:
      dest: /etc/hosts
      line: '{{ undercloud_hosts_entries | join('''') }}'
      state: present
    name: Make sure the Undercloud hostname is included in /etc/hosts
    when:
    - undercloud_hosts_entries is defined
  - name: Set container_registry_insecure_registries fact.
    set_fact:
      container_registry_insecure_registries: []
  - include_role:
      name: tripleo-podman
      tasks_from: tripleo_podman_install.yml
    vars:
      tripleo_container_registry_insecure_registries: '{{ container_registry_insecure_registries
        }}'
  name: Run podman install
  when:
  - step|int == 1
- block:
  - name: Check if pcs is present
    register: pcs_stat
    stat:
      path: /usr/sbin/pcs
  - name: Stop pacemaker cluster before stopping all docker containers
    pacemaker_cluster: state=offline
    when: pcs_stat.stat.exists
  - command: /usr/sbin/pcs cluster destroy
    name: Destroy pacemaker cluster
    when: pcs_stat.stat.exists
  - include_role:
      name: tripleo-podman
      tasks_from: tripleo_docker_stop.yml
    name: Stop all services by stopping all docker containers
    tags:
    - never
    - system_upgrade
    - system_upgrade_prepare
  name: system_upgrade_prepare step 2
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  when:
  - step|int == 2
- block:
  - command: systemctl is-enabled --quiet snmpd
    failed_when: false
    name: Check if snmpd is enabled
    register: snmpd_enabled_result
  - name: Set fact snmpd_enabled
    set_fact:
      snmpd_enabled: '{{ snmpd_enabled_result.rc == 0 }}'
  when: step|int == 0
- name: Stop snmp service
  service: name=snmpd state=stopped
  when:
  - step|int == 1
  - snmpd_enabled|bool
- block:
  - args:
      creates: /etc/sysconfig/ip6tables.n-o-upgrade
    name: blank ipv6 rule before activating ipv6 firewall.
    shell: cat /etc/sysconfig/ip6tables > /etc/sysconfig/ip6tables.n-o-upgrade; cat</dev/null>/etc/sysconfig/ip6tables
  - name: cleanup unmanaged rules pushed by iptables-services
    shell: "iptables -C INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT &>/dev/null\
      \ && \\\n  iptables -D INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\n\
      iptables -C INPUT -p icmp -j ACCEPT &>/dev/null && \\\n  iptables -D INPUT -p\
      \ icmp -j ACCEPT\niptables -C INPUT -i lo -j ACCEPT &>/dev/null && \\\n  iptables\
      \ -D INPUT -i lo -j ACCEPT\niptables -C INPUT -p tcp -m state --state NEW -m\
      \ tcp --dport 22 -j ACCEPT &>/dev/null && \\\n  iptables -D INPUT -p tcp -m\
      \ state --state NEW -m tcp --dport 22 -j ACCEPT\niptables -C INPUT -j REJECT\
      \ --reject-with icmp-host-prohibited &>/dev/null && \\\n  iptables -D INPUT\
      \ -j REJECT --reject-with icmp-host-prohibited\niptables -C FORWARD -j REJECT\
      \ --reject-with icmp-host-prohibited &>/dev/null && \\\n  iptables -D FORWARD\
      \ -j REJECT --reject-with icmp-host-prohibited\n\nsed -i '/^-A INPUT -m state\
      \ --state RELATED,ESTABLISHED -j ACCEPT$/d' /etc/sysconfig/iptables\nsed -i\
      \ '/^-A INPUT -p icmp -j ACCEPT$/d' /etc/sysconfig/iptables\nsed -i '/^-A INPUT\
      \ -i lo -j ACCEPT$/d' /etc/sysconfig/iptables\nsed -i '/^-A INPUT -p tcp -m\
      \ state --state NEW -m tcp --dport 22 -j ACCEPT$/d' /etc/sysconfig/iptables\n\
      sed -i '/^-A INPUT -j REJECT --reject-with icmp-host-prohibited$/d' /etc/sysconfig/iptables\n\
      sed -i '/^-A FORWARD -j REJECT --reject-with icmp-host-prohibited$/d' /etc/sysconfig/iptables\n\
      \nip6tables -C INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT &>/dev/null\
      \ && \\\n  ip6tables -D INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\n\
      ip6tables -C INPUT -p ipv6-icmp -j ACCEPT &>/dev/null && \\\n  ip6tables -D\
      \ INPUT -p ipv6-icmp -j ACCEPT\nip6tables -C INPUT -i lo -j ACCEPT &>/dev/null\
      \ && \\\n  ip6tables -D INPUT -i lo -j ACCEPT\nip6tables -C INPUT -p tcp -m\
      \ state --state NEW -m tcp --dport 22 -j ACCEPT &>/dev/null && \\\n  ip6tables\
      \ -D INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT\nip6tables\
      \ -C INPUT -d fe80::/64 -p udp -m udp --dport 546 -m state --state NEW -j ACCEPT\
      \ &>/dev/null && \\\n  ip6tables -D INPUT -d fe80::/64 -p udp -m udp --dport\
      \ 546 -m state --state NEW -j ACCEPT\nip6tables -C INPUT -j REJECT --reject-with\
      \ icmp6-adm-prohibited &>/dev/null && \\\n  ip6tables -D INPUT -j REJECT --reject-with\
      \ icmp6-adm-prohibited\nip6tables -C FORWARD -j REJECT --reject-with icmp6-adm-prohibited\
      \ &>/dev/null && \\\n  ip6tables -D FORWARD -j REJECT --reject-with icmp6-adm-prohibited\n\
      \nsed -i '/^-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT$/d' /etc/sysconfig/ip6tables\n\
      sed -i '/^-A INPUT -p ipv6-icmp -j ACCEPT$/d' /etc/sysconfig/ip6tables\nsed\
      \ -i '/^-A INPUT -i lo -j ACCEPT$/d' /etc/sysconfig/ip6tables\nsed -i '/^-A\
      \ INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT$/d' /etc/sysconfig/ip6tables\n\
      sed -i '/^-A INPUT -d fe80::\\/64 -p udp -m udp --dport 546 -m state --state\
      \ NEW -j ACCEPT$/d' /etc/sysconfig/ip6tables\nsed -i '/^-A INPUT -j REJECT --reject-with\
      \ icmp6-adm-prohibited$/d' /etc/sysconfig/ip6tables\nsed -i '/^-A FORWARD -j\
      \ REJECT --reject-with icmp6-adm-prohibited$/d' /etc/sysconfig/ip6tables"
  when: step|int == 3
- name: Gather missing facts
  setup:
    gather_subset: distribution
  tags:
  - always
  when: ansible_facts['distribution'] is not defined or ansible_facts['distribution_major_version']
    is not defined
- name: Set leapp facts
  set_fact:
    upgrade_leapp_command_options: ''
    upgrade_leapp_debug: true
    upgrade_leapp_devel_skip: ''
    upgrade_leapp_enabled: "{{ _upgradeLeappEnabled | bool and\n   ansible_facts['distribution']\
      \ == 'RedHat' and\n   ansible_facts['distribution_major_version'] is version('7',\
      \ '==') }}"
    upgrade_leapp_post_reboot_delay: 120
    upgrade_leapp_reboot_timeout: 3600
  tags:
  - always
  vars:
    _upgradeLeappEnabled: false
- block:
  - ignore_errors: true
    name: Hack around broken ceph-common rpm removing /etc/ceph /var/lib/ceph
    shell: 'rpm -e --nodeps --noscripts ceph-common

      '
  - name: remove all OpenStack packages
    shell: yum -y remove *el7ost* galera* xinetd* haproxy* httpd kernel-devel mysql*
      pacemaker* python-jsonpointer qemu-kvm-common-rhev qemu-img-rhev rabbit* redis*
      -- -*openvswitch* -python-docker -python-PyMySQL -python-pysocks -python2-asn1crypto
      -python2-babel -python2-cffi -python2-cryptography -python2-dateutil -python2-idna
      -python2-ipaddress -python2-jinja2 -python2-jsonpatch -python2-markupsafe -python2-pyOpenSSL
      -python2-requests -python2-six -python2-urllib3 -python2-chardet
  - name: Run LeappRepoInitCommand
    shell: '#!/bin/bash


      '
  - name: Check if system was booted via EFI
    register: efi
    stat:
      path: /sys/firmware/efi
  - failed_when: false
    name: Check if efi partition is present in /etc/fstab
    register: efi_fstab
    shell: 'grep efi /etc/fstab

      '
  - failed_when: false
    name: Find out the UUID of UEFI device
    register: efi_dev
    shell: 'blkid -s UUID -o value "$(blkid -t TYPE=vfat | grep -i efi | cut -d '':''
      -f1)"

      '
  - failed_when: false
    name: Check if red is in efibootmgr
    register: efi_broken
    shell: 'efibootmgr | grep "red$"

      '
  - block:
    - copy:
        dest: /tmp/workaround_1925078_redhat/
        remote_src: true
        src: /boot/efi/EFI/redhat/
      name: Copy /boot/efi/EFI/redhat to /tmp
    - lineinfile:
        dest: /etc/fstab
        line: UUID={{ efi_dev.stdout }} /boot/efi vfat umask=0077 0 1
      name: Insert /etc/fstab record
    - command: mount /boot/efi
      name: Mount the /boot/efi
    - copy:
        dest: /boot/efi/EFI/redhat/
        remote_src: true
        src: /tmp/workaround_1925078_redhat/
      name: Copy /tmp/redhat to /boot/efi/EFI/redhat
    - name: Create boot record
      shell: 'DEVICE_PATH="$(blkid -t TYPE=vfat | grep -i efi | cut -d '':'' -f1)"

        DEVICE="$(lsblk -no pkname $DEVICE_PATH)"

        PARTITION="$(echo $DEVICE_PATH | awk ''{print $NF}'' FS=/$DEVICE)"

        efibootmgr -c -L ''Red Hat Enterprise Linux'' -d $(echo $DEVICE_PATH | sed
        s/$PARTITION\$//) -p $PARTITION -l ''\EFI\redhat\shimx64.efi''

        '
    - command: grub2-mkconfig -o /boot/efi/EFI/redhat/grub.cfg
      name: Create grub config file
    - command: rmmod btrfs
      failed_when: false
      name: Remove btrfs module in case fuse just loaded it
    - name: Set workaround_1925078_fired
      set_fact:
        workaround_1925078_fired: true
    when:
    - efi_fstab.rc is defined
    - efi_dev.rc is defined
    - efi_broken.rc is defined
    - efi.stat.exists|bool
    - efi_fstab.rc == 1
    - efi_dev.rc == 0
    - efi_broken.rc == 0
  - name: install leapp
    package:
      name: leapp
      state: latest
  - delegate_to: undercloud
    find:
      paths: /etc/leapp/files
      patterns: '*'
    name: Retrieve files in /etc/leapp/files
    register: uc_leapp_files
  - delegate_to: undercloud
    fetch:
      dest: '{{ playbook_dir }}'
      src: '{{ item.path }}'
    loop: '{{ uc_leapp_files.files }}'
    name: Fetch the Leapp data from undercloud
  - copy:
      dest: '{{ item.path }}'
      src: '{{ playbook_dir }}/{{ inventory_hostname }}/{{ item.path }}'
    loop: '{{ uc_leapp_files.files }}'
    name: Copy the Leapp data from undercloud
  - name: Run LeappInitCommand
    shell: '#!/bin/bash


      '
  - file:
      path: /etc/modules-load.d/nf_conntrack_proto_sctp.conf
      state: absent
    name: Remove obsolete nf_conntrack_proto_sctp from /etc/modules-load.d/
  - lineinfile:
      line: '{{ item }}'
      path: /etc/leapp/transaction/to_remove
    loop: '{{ pkg_to_remove }}'
    name: add packages into Leapp's to_remove file
    vars:
      pkg_to_remove: []
  - lineinfile:
      line: '{{ item }}'
      path: /etc/leapp/transaction/to_install
    loop: '{{ pkg_to_install }}'
    name: add packages into Leapp's to_install file
    vars:
      pkg_to_install: []
  - name: check sshd_config file
    register: sshd_config_result
    stat:
      path: /etc/ssh/sshd_config
  - lineinfile:
      line: PermitRootLogin without-password
      path: /etc/ssh/sshd_config
      regexp: ^(# *)?PermitRootLogin
    name: add PermitRootLogin option for leapp
  name: system_upgrade_prepare step 3
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  when:
  - step|int == 3
  - upgrade_leapp_enabled
- block:
  - ignore_errors: true
    mount: path=/var/lib/glance/images state=absent
    name: unmount and remove nfs glance entry
  - ignore_errors: true
    mount: path="{{glance_node_staging_uri[7:]}}" state=absent
    name: unmount and remove nfs glance staging entry
    vars:
      glance_node_staging_uri: file:///var/lib/glance/staging
  - ignore_errors: true
    mount: path=/var/lib/nova/instances state=absent
    name: unmount and remove nfs nova entry
  - lineinfile:
      path: /usr/share/leapp-repository/repositories/system_upgrade/el7toel8/actors/kernel/checkkerneldrivers/files/removed_drivers.txt
      regexp: '{{ item }}'
      state: absent
    loop: '{{ modules_to_unload }}'
    name: Remove kernel drivers from Leapp removed_drivers.txt before running Leapp
    vars:
      modules_to_unload:
      - floppy
      - pata_acpi
  - name: set leapp options
    shell: 'leapp answer --section remove_pam_pkcs11_module_check.confirm=True --add

      '
  - name: run leapp upgrade (download packages)
    shell: '{% if upgrade_leapp_devel_skip|default(false) %}{{ upgrade_leapp_devel_skip
      }}{% endif %} leapp upgrade {% if upgrade_leapp_debug|default(true) %}--debug{%
      endif %} {% if upgrade_leapp_command_options|default(false) %}{{ upgrade_leapp_command_options
      }}{% endif %}

      '
  name: system_upgrade_prepare step 4
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  when:
  - step|int == 4
  - upgrade_leapp_enabled
- block:
  - block:
    - name: null
      shell: 'NEXT_BOOT="$(efibootmgr -v | grep \\redhat | awk -F''[ t*]'' ''{print
        $2}'')"

        efibootmgr -n $NEXT_BOOT

        '
    - name: Stat /boot/grub2/grubenv
      register: grubenv
      stat:
        path: /boot/grub2/grubenv
    - copy:
        dest: /boot/efi/EFI/redhat/grubenv
        remote_src: true
        src: /boot/grub2/grubenv
      name: Copy /boot/grub2/grubenv to /boot/efi/EFI/redhat/grubenv
      when: grubenv.stat.islnk is defined and grubenv.stat.islnk == False
    name: Reset boot order if WA#1925078 fired and fix grubenv
    when:
    - workaround_1925078_fired is defined
    - workaround_1925078_fired|bool
  - name: reboot to perform the upgrade
    reboot:
      post_reboot_delay: '{{ upgrade_leapp_post_reboot_delay }}'
      reboot_timeout: '{{upgrade_leapp_reboot_timeout}}'
      test_command: systemctl is-system-running | grep -e running -e degraded
  - name: Set the python to python3
    shell: alternatives --set python /usr/bin/python3
    vars:
      ansible_python_interpreter: /usr/bin/python3
  name: system_upgrade_run step 4
  tags:
  - never
  - system_upgrade
  - system_upgrade_run
  - system_upgrade_reboot
  when:
  - step|int == 4
  - upgrade_leapp_enabled
- block:
  - name: Run UpgradeInitCommand
    shell: '#!/bin/bash


      '
  - name: Run UpgradeInitCommonCommand
    shell: '#!/bin/bash


      '
  - dnf:
      name: '@{{ item.module }}:{{ item.stream }}/{{ item.profile|default(''common'')
        }}'
      state: present
    loop: '{{ dnf_module_list|list }}'
    name: Ensure DNF modules have the right stream
    vars:
      dnf_module_list: []
    when:
    - ansible_facts['distribution_major_version'] is version('8', '>=')
    - dnf_module_list|length > 0
  - delay: 10
    name: Ensure EL modules are in proper state
    register: _dnf_distro_sync
    retries: 5
    shell: dnf -y distro-sync
    until: _dnf_distro_sync is success
    when: ansible_facts['distribution_major_version'] == '8'
  - name: Clean up Python 2 packages
    package:
      name: python2-*
      state: absent
    when: ansible_facts['distribution_major_version'] == '8'
  - name: Ensure TripleO prerequisite packages are installed
    package:
      name:
      - jq
      - lvm2
      - net-snmp
      - openstack-selinux
      - os-net-config
      - puppet-tripleo
      - python3-heat-agent*
      - rsync
      state: present
    when: ansible_facts['distribution_major_version'] is version('8', '==')
  name: Package and repo update tasks
  when: step|int == 0
- name: Special treatment for OpenvSwitch
  register: ovs_upgrade
  tripleo_ovs_upgrade: null
  when:
  - step|int == 2
- name: Always ensure the openvswitch service is enabled and running after upgrades
  service:
    enabled: true
    name: openvswitch
    state: started
  when:
  - step|int == 2
  - ovs_upgrade.changed|bool
- name: Install libibverbs (https://bugs.launchpad.net/tripleo/+bug/1817743)
  package:
    name: libibverbs
    state: installed
  when: step|int == 2
- name: Check for os-net-config upgrade
  register: os_net_config_need_upgrade
  shell: yum check-upgrade | awk '/os-net-config/{print}'
  when: step|int == 3
- failed_when: false
  name: Check that os-net-config has configuration
  register: os_net_config_has_config
  shell: test -s /etc/os-net-config/config.json
  when: step|int == 3
- block:
  - name: Upgrade os-net-config
    package: name=os-net-config state=latest
  - changed_when: os_net_config_upgrade.rc == 2
    command: os-net-config --no-activate -c /etc/os-net-config/config.json -v --detailed-exit-codes
    failed_when: os_net_config_upgrade.rc not in [0,2]
    name: take new os-net-config parameters into account now
    register: os_net_config_upgrade
  when:
  - step|int == 3
  - os_net_config_need_upgrade.stdout
  - os_net_config_has_config.rc == 0
- name: Set boolean skip_package_update
  set_fact:
    skip_package_update: false
- name: Update all packages
  when:
  - step|int == 3
  - not skip_package_update|bool
  yum:
    exclude: ansible
    name: '*'
    state: latest
- block:
  - failed_when: false
    name: Check ovn_controller is running in docker
    register: ovn_controller_running
    shell: 'docker ps | grep ovn_controller

      '
  - command: docker update --restart=no ovn_controller
    name: Disable autorestart on ovn_controller container
    when: ovn_controller_running.rc == 0
  - name: Tell ovn_controller to clean up and stop
    shell: 'docker exec -u root ovn_controller bash -c "if [ -f /usr/bin/ovn-appctl
      ] ; then ovn-appctl -t ovn-controller exit ; else ovs-appctl -t ovn-controller
      exit ; fi"

      '
    when: ovn_controller_running.rc == 0
  name: ovn_controller system_upgrade_prepare step 1
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  when:
  - step|int == 1
- block:
  - failed_when: false
    name: Check if ovn_controller is runing with proper image
    register: hybrid_ovn_controller
    shell: docker ps | grep "{{ovn_controller_image}}"
  - block:
    - name: Update the ovn_controller paunch image in config
      shell: "set -o pipefail\njq '.ovn_controller.image = \"{{ ovn_controller_image\
        \ }}\" |\n    .ovn_controller.volumes += [\"/var/lib/openvswitch/ovn:/run/ovn:shared\"\
        , \"/var/log/containers/openvswitch:/var/log/ovn\"] |\n    {\"ovn_controller\"\
        : .ovn_controller }' \\\n/var/lib/tripleo-config/docker-container-startup-config-step_4.json\
        \ >\\\n/var/lib/tripleo-config/docker-container-hybrid_ovn_controller.json\n"
    - lineinfile:
        dest: /etc/hosts
        line: '{{ undercloud_hosts_entries | join('''') }}'
        state: present
      name: Make sure the Undercloud hostname is included in /etc/hosts
      when:
      - undercloud_hosts_entries is defined
    - name: Set container_registry_insecure_registries fact.
      set_fact:
        container_registry_insecure_registries: []
    - name: Set container_registry_insecure registries
      shell: crudini --set /etc/containers/registries.conf registries.insecure registries
        "[{{ container_registry_insecure_registries | map('regex_replace', '(.*)',
        "'\1'") | join(',') }}]"
      when: container_registry_insecure_registries != []
    - args:
        executable: /usr/bin/bash
      name: Restart docker and apply the paunch config
      shell: "set -o pipefail\n# Get list of running containers\nRUNNING=\"$( docker\
        \ ps --format '{{ '{{' }}.Names{{ '}}' }}' )\"\n# Restart docker\nsystemctl\
        \ restart docker\n# Compare running containers now vs before\nTO_STOP=\"$(grep\
        \ -v -f <(echo \"${RUNNING}\")  <(docker ps --format '{{ '{{' }}.Names{{ '}}'\
        \ }}'))\"\n# Check if we need to stop anything and stop it\nif [ -n \"${TO_STOP}\"\
        \ ]; then\n  echo \"${TO_STOP}\" | xargs -r docker stop\nfi\n"
      when: container_registry_insecure_registries != []
    - docker_container:
        name: ovn_controller
        state: absent
      name: Remove ovn_controller container before applying new paunch config
    - name: Apply paunch config if insecure registries are empty
      shell: 'paunch apply --file /var/lib/tripleo-config/docker-container-hybrid_ovn_controller.json
        --config-id hybrid_ovn_controller

        '
    name: Implement the hybrid state for ovn_controller
    when: hybrid_ovn_controller.rc != 0
  - name: Get ovn remote setting
    register: ovn_remote
    shell: 'ovs-vsctl get open . external_ids:ovn-remote

      '
  - name: Set fact - OVN SB connection string
    set_fact:
      ovn_sb_conn_str: '{{ [enable_internal_tls | bool | ternary(''ssl'',''tcp''),
        ovn_dbs_vip | ipwrap, service_configs[''ovn::southbound::port'']] | join('':'')
        }}'
  - name: Set new ovn remote setting
    shell: 'ovs-vsctl set open . external_ids:ovn-remote="{{ ovn_sb_conn_str }}"

      '
    when: ovn_sb_conn_str not in ovn_remote.stdout
  - name: Update OVNIntegrationBridge protocols to OpenFlow13,OpenFlow15
    shell: ovs-vsctl set bridge {{ ovn_interaction_bridge }} protocols="OpenFlow13,OpenFlow15"
  name: Switch ovn-controller to hybrid state
  tags:
  - never
  - nova_hybrid_state
  vars:
    ovn_controller_image: registry.redhat.io/rhosp-rhel8/openstack-ovn-controller:16.2
    ovn_interaction_bridge: br-int
  when:
  - step|int == 0
  - ansible_facts['distribution'] == 'RedHat'
  - ansible_facts['distribution_major_version'] is version('7', '==')
- block:
  - name: Set fact - OVN SB connection string
    set_fact:
      ovn_sb_conn_str: '{{ [enable_internal_tls | bool | ternary(''ssl'',''tcp''),
        ovn_dbs_vip | ipwrap, service_configs[''ovn::southbound::port'']] | join('':'')
        }}'
  - ini_file:
      option: ovn_sb_connection
      path: /var/lib/config-data/puppet-generated/neutron/etc/neutron/plugins/networking-ovn/networking-ovn-metadata-agent.ini
      section: ovn
      value: '{{ ovn_sb_conn_str }}'
    name: Set new ovn remote setting in networking-ovn-metadata-agent.ini
    register: ini_read_result
  - docker_container:
      comparisons:
        '*': ignore
      name: ovn_metadata_agent
      restart: true
      state: started
    name: Restart ovn_metadata_agent container to apply change in networking-ovn-metadata-agent.ini
    when: ini_read_result is changed
  name: Switch ovn remote setting
  tags:
  - never
  - nova_hybrid_state
  when: step|int == 0
