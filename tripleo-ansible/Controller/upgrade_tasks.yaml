- block:
  - name: fix grub entries to have name start with GRUB_
    replace:
      path: /etc/default/grub
      regexp: ^(TRIPLEO_HEAT_TEMPLATE_KERNEL_ARGS)(.*)
      replace: GRUB_\1\2
  - name: fix grub entries in append statement
    replace:
      path: /etc/default/grub
      regexp: (.*){(TRIPLEO_HEAT_TEMPLATE_KERNEL_ARGS)}(.*)
      replace: \1{GRUB_\2}\3
  name: upgrade prepare for leapp to align kernel arg shortcommings in leapp
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  when:
  - step|int == 3
  - upgrade_leapp_enabled
- block:
  - failed_when: false
    name: Get cinder_volume image id currently used by pacemaker
    register: cinder_volume_image_current_res
    shell: pcs resource config openstack-cinder-volume | grep -Eo 'image=[^ ]+' |
      awk -F= '{print $2;}'
  - name: cinder_volume image facts
    set_fact:
      cinder_volume_image_current: '{{cinder_volume_image_current_res.stdout}}'
      cinder_volume_image_latest: cluster.common.tag/openstack-cinder-volume:pcmklatest
  - import_role:
      name: tripleo-container-tag
    name: Temporarily tag the current cinder_volume image id with the upgraded image
      name
    vars:
      container_image: '{{cinder_volume_image_current}}'
      container_image_latest: '{{cinder_volume_image_latest}}'
      pull_image: false
    when:
    - cinder_volume_image_current != ''
    - cinder_volume_image_current != cinder_volume_image_latest
  - changed_when: false
    failed_when: false
    name: Check openstack-cinder-volume cluster resource status
    register: cinder_volume_pcs_res_result
    shell: pcs resource config openstack-cinder-volume
  - name: Set fact cinder_volume_pcs_res
    set_fact:
      cinder_volume_pcs_res: '{{cinder_volume_pcs_res_result.rc == 0}}'
  - name: set is_cinder_volume_bootstrap_node fact
    set_fact: is_cinder_volume_bootstrap_node={{cinder_volume_short_bootstrap_node_name|lower
      == ansible_facts['hostname']|lower}}
    tags: common
  name: Prepare switch of cinder_volume image name
  when:
  - step|int == 0
- block:
  - name: Disable the cinder_volume cluster resource before container upgrade
    pacemaker_resource:
      resource: openstack-cinder-volume
      state: disable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
  - command: pcs resource bundle update openstack-cinder-volume container image={{cinder_volume_image_latest}}
    name: pcs resource bundle update cinder_volume for new container image name
  - name: Enable the cinder_volume cluster resource
    pacemaker_resource:
      resource: openstack-cinder-volume
      state: enable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
  name: Update cinder_volume pcs resource bundle for new container image
  when:
  - step|int == 1
  - is_cinder_volume_bootstrap_node
  - cinder_volume_pcs_res|bool
  - cinder_volume_image_current != cinder_volume_image_latest
- block:
  - name: set cinder_volume upgrade node facts in a single-node environment
    set_fact:
      cacheable: false
      cinder_volume_node_names_upgraded: '{{ cinder_volume_node_names | default([])
        }}'
      cinder_volume_short_node_names_upgraded: '{{ cinder_volume_short_node_names
        }}'
    when: groups['cinder_volume'] | length <= 1
  - loop: '{{ cinder_volume_node_names }}'
    name: set cinder_volume upgrade node facts from the limit option
    set_fact:
      cacheable: false
      cinder_volume_node_names_upgraded: '{{ cinder_volume_node_names_upgraded|default([])
        + [item] }}'
      cinder_volume_short_node_names_upgraded: '{{ cinder_volume_short_node_names_upgraded|default([])
        + [item.split(''.'')[0]] }}'
    when:
    - groups['cinder_volume'] | length > 1
    - item.split('.')[0] in ansible_limit.split(':')
  - fail:
      msg: 'You can''t upgrade cinder_volume without staged upgrade.  You need to
        use the limit option in order to do so.

        '
    when: cinder_volume_short_node_names_upgraded is not defined or cinder_volume_short_node_names_upgraded
      | length == 0 or cinder_volume_node_names_upgraded is not defined or cinder_volume_node_names_upgraded
      | length == 0
  - debug:
      msg: Prepare cinder_volume upgrade for {{ cinder_volume_short_node_names_upgraded
        }}
  - include_role:
      name: tripleo-container-rm
    name: remove cinder_volume init container on upgrade-scaleup to force re-init
    vars:
      tripleo_containers_to_rm:
      - cinder_volume_init_bundle
    when:
    - cinder_volume_short_node_names_upgraded | length > 1
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the cinder_volume short name to hiera data for the upgrade.
    vars:
      tripleo_upgrade_key: cinder_volume_short_node_names_override
      tripleo_upgrade_value: '{{ cinder_volume_short_node_names_upgraded }}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the cinder_volume long name to hiera data for the upgrade
    vars:
      tripleo_upgrade_key: cinder_volume_node_names_override
      tripleo_upgrade_value: '{{ cinder_volume_node_names_upgraded }}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: remove.yml
    loop:
    - cinder_volume_short_node_names_override
    - cinder_volume_node_names_override
    name: remove the extra hiera data needed for the upgrade.
    vars:
      tripleo_upgrade_key: '{{ item }}'
    when: cinder_volume_short_node_names_upgraded | length == cinder_volume_node_names
      | length
  name: Create hiera data to upgrade cinder_volume in a stepwise manner.
  when:
  - step|int == 1
  - cluster_recreate|bool
- block:
  - name: Get container cinder_volume image
    set_fact:
      cinder_volume_image: registry.redhat.io/rhosp-rhel8/openstack-cinder-volume:16.2
      cinder_volume_image_latest: cluster.common.tag/openstack-cinder-volume:pcmklatest
  - command: '{{container_cli}} pull {{cinder_volume_image}}'
    delay: 3
    name: Pull latest cinder_volume images
    register: result
    retries: 3
    until: result.rc == 0
  - failed_when: false
    name: Get previous cinder_volume image id
    register: old_cinder_volume_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{cinder_volume_image_latest}}'
  - name: Get new cinder_volume image id
    register: new_cinder_volume_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{cinder_volume_image}}'
  - include_role:
      name: tripleo-container-tag
    name: Retag pcmklatest to latest cinder_volume image
    vars:
      container_image: '{{cinder_volume_image}}'
      container_image_latest: '{{cinder_volume_image_latest}}'
    when:
    - old_cinder_volume_image_id.stdout != new_cinder_volume_image_id.stdout
  name: Retag the pacemaker image if containerized
  when:
  - step|int == 3
- block:
  - failed_when: false
    name: Get haproxy image id currently used by pacemaker
    register: haproxy_image_current_res
    shell: pcs resource config haproxy-bundle | grep -Eo 'image=[^ ]+' | awk -F= '{print
      $2;}'
  - name: Image facts for haproxy
    set_fact:
      haproxy_image_current: '{{haproxy_image_current_res.stdout}}'
      haproxy_image_latest: cluster.common.tag/openstack-haproxy:pcmklatest
  - import_role:
      name: tripleo-container-tag
    name: Temporarily tag the current haproxy image id with the upgraded image name
    vars:
      container_image: '{{haproxy_image_current}}'
      container_image_latest: '{{haproxy_image_latest}}'
      pull_image: false
    when:
    - haproxy_image_current != ''
    - haproxy_image_current != haproxy_image_latest
  - changed_when: false
    failed_when: false
    name: Check haproxy cluster resource status
    register: haproxy_pcs_res_result
    shell: pcs resource config haproxy-bundle
  - name: Set upgrade haproxy facts
    set_fact:
      haproxy_pcs_res: '{{haproxy_pcs_res_result.rc == 0}}'
      is_haproxy_bootstrap_node: '{{haproxy_short_bootstrap_node_name|lower == ansible_facts[''hostname'']|lower}}'
  name: Prepare switch of haproxy image name
  when:
  - step|int == 0
- block:
  - name: Disable the haproxy cluster resource before container upgrade
    pacemaker_resource:
      resource: haproxy-bundle
      state: disable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
  - block:
    - command: cibadmin --query --xpath "//storage-mapping[@id='haproxy-var-lib']"
      failed_when: false
      name: Check haproxy stats socket configuration in pacemaker
      register: haproxy_stats_exposed
    - command: cibadmin --query --xpath "//storage-mapping[@id='haproxy-cert']"
      failed_when: false
      name: Check haproxy public certificate configuration in pacemaker
      register: haproxy_cert_mounted
    - command: pcs resource bundle update haproxy-bundle storage-map add id=haproxy-var-lib
        source-dir=/var/lib/haproxy target-dir=/var/lib/haproxy options=rw
      name: Add a bind mount for stats socket in the haproxy bundle
      when: haproxy_stats_exposed.rc == 6
    - name: Set HAProxy public cert volume mount fact
      set_fact:
        haproxy_public_cert_path: /etc/pki/tls/private/overcloud_endpoint.pem
        haproxy_public_tls_enabled: false
    - command: pcs resource bundle update haproxy-bundle storage-map add id=haproxy-cert
        source-dir={{ haproxy_public_cert_path }} target-dir=/var/lib/kolla/config_files/src-tls/{{
        haproxy_public_cert_path }} options=ro
      name: Add a bind mount for public certificate in the haproxy bundle
      when:
      - haproxy_cert_mounted.rc == 6
      - haproxy_public_tls_enabled|bool
    name: Expose HAProxy stats socket on the host and mount TLS cert if needed
  - command: pcs resource bundle update haproxy-bundle container image={{haproxy_image_latest}}
    name: Update the haproxy bundle to use the new container image name
  - name: Enable the haproxy cluster resource
    pacemaker_resource:
      resource: haproxy-bundle
      state: enable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
  name: Update haproxy pcs resource bundle for new container image
  when:
  - step|int == 1
  - is_haproxy_bootstrap_node|bool
  - haproxy_pcs_res|bool
  - haproxy_image_current != haproxy_image_latest
- block:
  - name: set haproxy upgrade node facts in a single-node environment
    set_fact:
      cacheable: false
      haproxy_short_node_names_upgraded: '{{ haproxy_short_node_names }}'
    when: groups['haproxy'] | length <= 1
  - loop: '{{ haproxy_short_node_names }}'
    name: set haproxy upgrade node facts from the limit option
    set_fact:
      cacheable: false
      haproxy_short_node_names_upgraded: '{{ haproxy_short_node_names_upgraded|default([])
        + [item.split(''.'')[0]] }}'
    when:
    - groups['haproxy'] | length > 1
    - item.split('.')[0] in ansible_limit.split(':')
  - fail:
      msg: 'You can''t upgrade haproxy without staged upgrade. You need to use the
        limit option in order to do so.

        '
    when: haproxy_short_node_names_upgraded is not defined or haproxy_short_node_names_upgraded
      | length == 0
  - debug:
      msg: Prepare haproxy upgrade for {{ haproxy_short_node_names_upgraded }}
  - include_role:
      name: tripleo-container-rm
    name: remove haproxy init container on upgrade-scaleup to force re-init
    vars:
      tripleo_containers_to_rm:
      - haproxy_init_bundle
    when:
    - haproxy_short_node_names_upgraded | length > 1
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the haproxy short name to hiera data for the upgrade.
    vars:
      tripleo_upgrade_key: haproxy_short_node_names_override
      tripleo_upgrade_value: '{{haproxy_short_node_names_upgraded}}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: remove.yml
    name: remove the extra hiera data needed for the upgrade.
    vars:
      tripleo_upgrade_key: haproxy_short_node_names_override
    when: haproxy_short_node_names_upgraded | length == haproxy_short_node_names |
      length
  name: Create hiera data to upgrade haproxy in a stepwise manner.
  when:
  - step|int == 1
  - cluster_recreate|bool
- block:
  - name: Get container haproxy image
    set_fact:
      haproxy_image: registry.redhat.io/rhosp-rhel8/openstack-haproxy:16.2
      haproxy_image_latest: cluster.common.tag/openstack-haproxy:pcmklatest
  - command: '{{container_cli}} pull {{haproxy_image}}'
    delay: 3
    name: Pull latest haproxy images
    register: result
    retries: 3
    until: result.rc == 0
  - failed_when: false
    name: Get previous haproxy image id
    register: old_haproxy_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{haproxy_image_latest}}'
  - name: Get new haproxy image id
    register: new_haproxy_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{haproxy_image}}'
  - include_role:
      name: tripleo-container-tag
    name: Retag pcmklatest to latest haproxy image
    vars:
      container_image: '{{haproxy_image}}'
      container_image_latest: '{{haproxy_image_latest}}'
    when:
    - old_haproxy_image_id.stdout != new_haproxy_image_id.stdout
  name: Retag the pacemaker image if containerized
  when:
  - step|int == 3
- block:
  - file:
      mode: 1777
      path: /var/tmp
      setype: tmp_t
      state: directory
    name: Reset selinux label on /var/tmp
  name: Anchor for upgrade and update tasks
  when: step|int == 0
- name: Gather missing facts
  setup:
    gather_subset: distribution
  tags:
  - never
  - nova_hybrid_state
  when: ansible_facts['distribution'] is not defined or ansible_facts['distribution_major_version']
    is not defined
- block:
  - failed_when: false
    name: Check if iscsid is running with proper image
    register: hybrid_iscsid
    shell: 'docker ps | grep "{{iscsid_image}}"

      '
  - block:
    - name: Update the iscsid paunch image in config
      shell: 'set -o pipefail

        jq ''.iscsid.image = "{{ iscsid_image }}" | {"iscsid": .iscsid }'' \

        /var/lib/tripleo-config/docker-container-startup-config-step_3.json >\

        /var/lib/tripleo-config/docker-container-hybrid_iscsid.json

        '
    - lineinfile:
        dest: /etc/hosts
        line: '{{ undercloud_hosts_entries | join('''') }}'
        state: present
      name: Make sure the Undercloud hostname is included in /etc/hosts
      when:
      - undercloud_hosts_entries is defined
    - name: Set container_registry_insecure_registries fact.
      set_fact:
        container_registry_insecure_registries: []
    - ini_file:
        option: registries
        path: /etc/containers/registries.conf
        section: registries.insecure
        value: '{{ container_registry_insecure_registries }}'
      name: Set container_registry_insecure registries
      register: ini_read_result
      when: container_registry_insecure_registries != []
    - args:
        executable: /usr/bin/bash
      name: Restart docker and apply the paunch config
      shell: "set -o pipefail\n# Get list of running containers\nRUNNING=\"$( docker\
        \ ps --format '{{ '{{' }}.Names{{ '}}' }}' )\"\n# Restart docker\nsystemctl\
        \ restart docker\n# Compare running containers now vs before\nTO_STOP=\"$(grep\
        \ -v -f <(echo \"${RUNNING}\")  <(docker ps --format '{{ '{{' }}.Names{{ '}}'\
        \ }}'))\"\n# Check if we need to stop anything and stop it\nif [ -n \"${TO_STOP}\"\
        \ ]; then\n  echo \"${TO_STOP}\" | xargs -r docker stop\nfi\n"
      when:
      - container_registry_insecure_registries != []
      - ini_read_result is changed
    - docker_container:
        name: iscsid
        state: absent
      name: Remove iscsid container before applying new paunch config
    - name: Apply paunch config for iscsid
      shell: paunch apply --file /var/lib/tripleo-config/docker-container-hybrid_iscsid.json
        --config-id hybrid_iscsid
    name: Implement the hybrid state (only if the compute is still Queens)
    when: hybrid_iscsid.rc != 0
  name: Switch iscsid to hybrid state
  tags:
  - never
  - nova_hybrid_state
  vars:
    iscsid_image: registry.redhat.io/rhosp-rhel8/openstack-iscsid:16.2
  when:
  - step|int == 0
  - ansible_facts['distribution'] == 'RedHat'
  - ansible_facts['distribution_major_version'] is version('7', '==')
- block:
  - include_role:
      name: tripleo-persist
      tasks_from: persist.yml
    name: Persist mysql data
    vars:
      tripleo_persist_dir: /var/lib/mysql
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  vars:
    mysql_upgrade_persist: false
  when:
  - step|int == 3
  - mysql_upgrade_persist
- block:
  - include_role:
      name: tripleo-persist
      tasks_from: restore.yml
    name: Restore mysql data
    vars:
      tripleo_persist_dir: /var/lib/mysql
  tags:
  - never
  - system_upgrade
  - system_upgrade_run
  vars:
    mysql_upgrade_persist: false
  when:
  - step|int == 5
  - mysql_upgrade_persist
- block:
  - failed_when: false
    name: Get galera image id currently used by pacemaker
    register: galera_image_current_res
    shell: pcs resource config galera-bundle | grep -Eo 'image=[^ ]+' | awk -F= '{print
      $2;}'
  - name: Image facts for galera
    set_fact:
      galera_image_current: '{{galera_image_current_res.stdout}}'
      galera_image_latest: cluster.common.tag/openstack-mariadb:pcmklatest
  - import_role:
      name: tripleo-container-tag
    name: Temporarily tag the current galera image id with the upgraded image name
    vars:
      container_image: '{{galera_image_current}}'
      container_image_latest: '{{galera_image_latest}}'
      pull_image: false
    when:
    - galera_image_current != ''
    - galera_image_current != galera_image_latest
  - changed_when: false
    failed_when: false
    name: Check galera cluster resource status
    register: galera_pcs_res_result
    shell: pcs resource config galera-bundle
  - name: Set fact galera_pcs_res
    set_fact:
      galera_pcs_res: '{{galera_pcs_res_result.rc == 0}}'
  - name: set is_mysql_bootstrap_node fact
    set_fact: is_mysql_bootstrap_node={{mysql_short_bootstrap_node_name|lower == ansible_facts['hostname']|lower}}
    tags: common
  name: Prepare switch of galera image name
  when:
  - step|int == 0
- block:
  - name: Disable the galera cluster resource before container upgrade
    pacemaker_resource:
      resource: galera
      state: disable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
  - block:
    - command: cibadmin --query --xpath "//storage-mapping[@id='mysql-log']"
      failed_when: false
      name: Check Mysql logging configuration in pacemaker
      register: mysql_logs_moved
    - block:
      - command: pcs resource bundle update galera-bundle storage-map add id=mysql-log
          source-dir=/var/log/containers/mysql target-dir=/var/log/mysql options=rw
        name: Add a bind mount for logging in the galera bundle
      - command: pcs resource update galera log=/var/log/mysql/mysqld.log
        name: Reconfigure Mysql log file in the galera resource agent
      name: Change Mysql logging configuration in pacemaker
      when: mysql_logs_moved.rc == 6
    name: Move Mysql logging to /var/log/containers
  - command: pcs resource bundle update galera-bundle container image={{galera_image_latest}}
    name: Update the galera bundle to use the new container image name
  - name: Enable the galera cluster resource
    pacemaker_resource:
      resource: galera
      state: enable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
  name: Update galera pcs resource bundle for new container image
  when:
  - step|int == 1
  - is_mysql_bootstrap_node|bool
  - galera_pcs_res|bool
  - galera_image_current != galera_image_latest
- block:
  - name: set mysql upgrade node facts in a single-node environment
    set_fact:
      cacheable: false
      mysql_node_names_upgraded: '{{ mysql_node_names }}'
      mysql_short_node_names_upgraded: '{{ mysql_short_node_names }}'
    when: groups['mysql'] | length <= 1
  - loop: '{{ mysql_node_names }}'
    name: set mysql upgrade node facts from the limit option
    set_fact:
      cacheable: false
      mysql_node_names_upgraded: '{{ mysql_node_names_upgraded|default([]) + [item]
        }}'
      mysql_short_node_names_upgraded: '{{ mysql_short_node_names_upgraded|default([])
        + [item.split(''.'')[0]] }}'
    when:
    - groups['mysql'] | length > 1
    - item.split('.')[0] in ansible_limit.split(':')
  - fail:
      msg: 'You can''t upgrade galera without staged upgrade. You need to use the
        limit option in order to do so.

        '
    when: mysql_short_node_names_upgraded is not defined or mysql_short_node_names_upgraded
      | length == 0 or mysql_node_names_upgraded is not defined or mysql_node_names_upgraded
      | length == 0
  - debug:
      msg: Prepare galera upgrade for {{ mysql_short_node_names_upgraded }}
  - include_role:
      name: tripleo-container-rm
    name: remove mysql init container on upgrade-scaleup to force re-init
    vars:
      tripleo_containers_to_rm:
      - mysql_wait_bundle
    when:
    - mysql_short_node_names_upgraded | length > 1
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the mysql short name to hiera data for the upgrade.
    vars:
      tripleo_upgrade_key: mysql_short_node_names_override
      tripleo_upgrade_value: '{{mysql_short_node_names_upgraded}}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the mysql long name to hiera data for the upgrade
    vars:
      tripleo_upgrade_key: mysql_node_names_override
      tripleo_upgrade_value: '{{mysql_node_names_upgraded}}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: remove.yml
    loop:
    - mysql_short_node_names_override
    - mysql_node_names_override
    name: remove the extra hiera data needed for the upgrade.
    vars:
      tripleo_upgrade_key: '{{item}}'
    when: mysql_short_node_names_upgraded | length == mysql_node_names | length
  name: Create hiera data to upgrade mysql in a stepwise manner.
  when:
  - step|int == 1
  - cluster_recreate|bool
- block:
  - name: Get container galera image
    set_fact:
      galera_image: registry.redhat.io/rhosp-rhel8/openstack-mariadb:16.2
      galera_image_latest: cluster.common.tag/openstack-mariadb:pcmklatest
  - command: '{{container_cli}} pull {{galera_image}}'
    delay: 3
    name: Pull latest galera images
    register: result
    retries: 3
    until: result.rc == 0
  - failed_when: false
    name: Get previous galera image id
    register: old_galera_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{galera_image_latest}}'
  - name: Get new galera image id
    register: new_galera_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{galera_image}}'
  - include_role:
      name: tripleo-container-tag
    name: Retag pcmklatest to latest galera image
    vars:
      container_image: '{{galera_image}}'
      container_image_latest: '{{galera_image_latest}}'
    when:
    - old_galera_image_id.stdout != new_galera_image_id.stdout
  name: Retag the pacemaker image if containerized
  when:
  - step|int == 3
- block:
  - name: Update host mariadb packages
    package: name=mariadb-server-galera state=latest
    when: step|int == 3
  - name: Mysql upgrade script
    set_fact:
      mysql_upgrade_script: 'kolla_set_configs

        if mysqladmin ping --silent; then exit 0; fi

        chown -R mysql:mysql /var/lib/mysql

        chown -R mysql:mysql /var/log/mysql

        mysqld_safe --user=mysql --wsrep-provider=none --skip-networking --wsrep-on=off
        --log-error=/var/log/mysql/mysqld-upgrade.log &


        #!/bin/bash


        set -e


        # Wait until we know the mysql server is up and responding

        timeout ${DB_MAX_TIMEOUT:-60} /bin/bash -c ''until mysqladmin -uroot ping
        2>/dev/null; do sleep 1; done''


        # After an upgrade, make sure that the running mysql had a chance to

        # update its data table on disk.

        mysql_upgrade


        # Upgrade to 10.3: the default table row format changed from COMPACT

        # to DYNAMIC, so upgrade the existing tables.

        compact_tables=$(mysql -se ''SELECT CONCAT("`",TABLE_SCHEMA,"`.`",TABLE_NAME,"`")
        FROM information_schema.tables WHERE ENGINE = "InnoDB" and ROW_FORMAT = "Compact";'');

        for i in $compact_tables; do echo converting row format of table $i; mysql
        -e "ALTER TABLE $i ROW_FORMAT=DYNAMIC;"; done;


        mysqladmin shutdown'
  - name: Bind mounts for temporary container
    set_fact:
      mysql_upgrade_db_bind_mounts:
      - /etc/hosts:/etc/hosts:ro
      - /etc/localtime:/etc/localtime:ro
      - /etc/pki/ca-trust/extracted:/etc/pki/ca-trust/extracted:ro
      - /etc/pki/ca-trust/source/anchors:/etc/pki/ca-trust/source/anchors:ro
      - /etc/pki/tls/certs/ca-bundle.crt:/etc/pki/tls/certs/ca-bundle.crt:ro
      - /etc/pki/tls/certs/ca-bundle.trust.crt:/etc/pki/tls/certs/ca-bundle.trust.crt:ro
      - /etc/pki/tls/cert.pem:/etc/pki/tls/cert.pem:ro
      - /dev/log:/dev/log
      - /etc/puppet:/etc/puppet:ro
      - /var/lib/kolla/config_files/mysql.json:/var/lib/kolla/config_files/config.json:rw,z
      - /var/lib/config-data/puppet-generated/mysql:/var/lib/kolla/config_files/src:ro,z
      - /var/lib/mysql:/var/lib/mysql:rw,z
      - /var/log/containers/mysql:/var/log/mysql:rw,z
  - environment:
      UPGRADE_SCRIPT: '{{ mysql_upgrade_script }}'
    name: Upgrade Mysql database from a temporary container
    shell: '{{ container_cli }} run --rm --log-driver=k8s-file --log-opt path=/var/log/containers/mysql/db-upgrade.log
      \ -u root --net=host -e "KOLLA_CONFIG_STRATEGY=COPY_ALWAYS" -v {{ mysql_upgrade_db_bind_mounts
      | join('' -v '')}} "cluster.common.tag/openstack-mariadb:pcmklatest" /bin/bash
      -ecx "$UPGRADE_SCRIPT"'
  name: Check and upgrade Mysql database after major version upgrade
  when: step|int == 3
- file:
    path: /etc/cron.daily/containers-tmpwatch
    state: absent
  name: Ensure old cron.daily is absent
  when: step|int == 1
- block:
  - failed_when: false
    name: Get ovn-dbs image id currently used by pacemaker
    register: ovn_dbs_image_current_res
    shell: pcs resource config ovn-dbs-bundle | grep -Eo 'image=[^ ]+' | awk -F= '{print
      $2;}'
  - name: ovn-dbs image facts
    set_fact:
      ovn_dbs_image: registry.redhat.io/rhosp-rhel8/openstack-ovn-northd:16.2
      ovn_dbs_image_current: '{{ovn_dbs_image_current_res.stdout}}'
      ovn_dbs_image_latest: cluster.common.tag/openstack-ovn-northd:pcmklatest
  - import_role:
      name: tripleo-container-tag
    name: Temporarily tag the current ovn_dbs image id with the upgraded image name
    vars:
      container_image: '{{ovn_dbs_image_current}}'
      container_image_latest: '{{ovn_dbs_image_latest}}'
      pull_image: false
    when:
    - ovn_dbs_image_current != ''
    - ovn_dbs_image_current != ovn_dbs_image_latest
  - changed_when: false
    failed_when: false
    name: Check ovn-dbs-bundle cluster resource status
    register: ovn_dbs_pcs_result
    shell: pcs resource config ovn-dbs-bundle
  - name: Set fact ovn_dbs_pcs_res
    set_fact:
      ovn_dbs_pcs_res: '{{ ovn_dbs_pcs_result.rc == 0 }}'
  name: Prepare switch of ovn-dbs image name
  when:
  - step|int == 0
- block:
  - name: Disable the ovn-dbs-bundle cluster resource before container upgrade
    pacemaker_resource:
      resource: ovn-dbs-bundle
      state: disable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
  - command: pcs resource bundle update ovn-dbs-bundle container image={{ovn_dbs_image_latest}}
    name: pcs resource bundle update ovn-dbs for new container image name
  - name: Enable the ovn-dbs-bundle cluster resource
    pacemaker_resource:
      resource: ovn-dbs-bundle
      state: enable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
    when: null
  name: Update ovn_dbs pcs resource bundle for new container image
  when:
  - step|int == 1
  - ovn_dbs_short_bootstrap_node_name|lower == ansible_facts['hostname']|lower
  - ovn_dbs_pcs_res|bool
  - ovn_dbs_image_current != ovn_dbs_image_latest
- block:
  - name: set ovn_dbs upgrade node facts in a single-node environment
    set_fact:
      cacheable: false
      ovn_dbs_short_node_names_upgraded: '{{ ovn_dbs_short_node_names }}'
    when: groups['ovn_dbs'] | length <= 1
  - loop: '{{ ovn_dbs_short_node_names }}'
    name: set ovn_dbs upgrade node facts from the limit option
    set_fact:
      cacheable: false
      ovn_dbs_short_node_names_upgraded: '{{ ovn_dbs_short_node_names_upgraded|default([])
        + [item.split(''.'')[0]] }}'
    when:
    - groups['ovn_dbs'] | length > 1
    - item.split('.')[0] in ansible_limit.split(':')
  - fail:
      msg: 'You can''t upgrade ovn_dbs without staged upgrade. You need to use the
        limit option in order to do so.

        '
    when: ovn_dbs_short_node_names_upgraded is not defined or ovn_dbs_short_node_names_upgraded
      | length == 0
  - debug:
      msg: Prepare ovn_dbs upgrade for {{ ovn_dbs_short_node_names_upgraded }}
  - include_role:
      name: tripleo-container-rm
    name: remove ovn_dbs init container on upgrade-scaleup to force re-init
    vars:
      tripleo_containers_to_rm:
      - ovn_dbs_init_bundle
    when:
    - ovn_dbs_short_node_names_upgraded | length > 1
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the ovn_dbs short name to hiera data for the upgrade.
    vars:
      tripleo_upgrade_key: ovn_dbs_short_node_names_override
      tripleo_upgrade_value: '{{ovn_dbs_short_node_names_upgraded}}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: remove.yml
    name: remove the extra hiera data needed for the upgrade.
    vars:
      tripleo_upgrade_key: ovn_dbs_short_node_names_override
    when: ovn_dbs_short_node_names_upgraded | length == ovn_dbs_short_node_names |
      length
  name: Create hiera data to upgrade ovn_dbs in a stepwise manner.
  when:
  - step|int == 1
  - cluster_recreate|bool
- block:
  - command: '{{container_cli}} pull {{ovn_dbs_image}}'
    delay: 3
    name: Pull latest ovn-dbs images
    register: result
    retries: 3
    until: result.rc == 0
  - failed_when: false
    name: Get previous ovn_dbs image id
    register: old_ovn_dbs_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{ovn_dbs_image_latest}}'
  - name: Get new ovn_dbs image id
    register: new_ovn_dbs_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{ovn_dbs_image}}'
  - include_role:
      name: tripleo-container-tag
    name: Retag pcmklatest to latest ovn_dbs image
    vars:
      container_image: '{{ovn_dbs_image}}'
      container_image_latest: '{{ovn_dbs_image_latest}}'
    when:
    - old_ovn_dbs_image_id.stdout != new_ovn_dbs_image_id.stdout
  name: Retag the pacemaker image if containerized
  when:
  - step|int == 3
- block:
  - failed_when: false
    name: Check ovn_controller is running in docker
    register: ovn_controller_running
    shell: 'docker ps | grep ovn_controller

      '
  - command: docker update --restart=no ovn_controller
    name: Disable autorestart on ovn_controller container
    when: ovn_controller_running.rc == 0
  - name: Tell ovn_controller to clean up and stop
    shell: 'docker exec -u root ovn_controller bash -c "if [ -f /usr/bin/ovn-appctl
      ] ; then ovn-appctl -t ovn-controller exit ; else ovs-appctl -t ovn-controller
      exit ; fi"

      '
    when: ovn_controller_running.rc == 0
  name: ovn_controller system_upgrade_prepare step 1
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  when:
  - step|int == 1
- block:
  - failed_when: false
    name: Check if ovn_controller is runing with proper image
    register: hybrid_ovn_controller
    shell: docker ps | grep "{{ovn_controller_image}}"
  - block:
    - name: Update the ovn_controller paunch image in config
      shell: "set -o pipefail\njq '.ovn_controller.image = \"{{ ovn_controller_image\
        \ }}\" |\n    .ovn_controller.volumes += [\"/var/lib/openvswitch/ovn:/run/ovn:shared\"\
        , \"/var/log/containers/openvswitch:/var/log/ovn\"] |\n    {\"ovn_controller\"\
        : .ovn_controller }' \\\n/var/lib/tripleo-config/docker-container-startup-config-step_4.json\
        \ >\\\n/var/lib/tripleo-config/docker-container-hybrid_ovn_controller.json\n"
    - lineinfile:
        dest: /etc/hosts
        line: '{{ undercloud_hosts_entries | join('''') }}'
        state: present
      name: Make sure the Undercloud hostname is included in /etc/hosts
      when:
      - undercloud_hosts_entries is defined
    - name: Set container_registry_insecure_registries fact.
      set_fact:
        container_registry_insecure_registries: []
    - name: Set container_registry_insecure registries
      shell: crudini --set /etc/containers/registries.conf registries.insecure registries
        "[{{ container_registry_insecure_registries | map('regex_replace', '(.*)',
        "'\1'") | join(',') }}]"
      when: container_registry_insecure_registries != []
    - args:
        executable: /usr/bin/bash
      name: Restart docker and apply the paunch config
      shell: "set -o pipefail\n# Get list of running containers\nRUNNING=\"$( docker\
        \ ps --format '{{ '{{' }}.Names{{ '}}' }}' )\"\n# Restart docker\nsystemctl\
        \ restart docker\n# Compare running containers now vs before\nTO_STOP=\"$(grep\
        \ -v -f <(echo \"${RUNNING}\")  <(docker ps --format '{{ '{{' }}.Names{{ '}}'\
        \ }}'))\"\n# Check if we need to stop anything and stop it\nif [ -n \"${TO_STOP}\"\
        \ ]; then\n  echo \"${TO_STOP}\" | xargs -r docker stop\nfi\n"
      when: container_registry_insecure_registries != []
    - docker_container:
        name: ovn_controller
        state: absent
      name: Remove ovn_controller container before applying new paunch config
    - name: Apply paunch config if insecure registries are empty
      shell: 'paunch apply --file /var/lib/tripleo-config/docker-container-hybrid_ovn_controller.json
        --config-id hybrid_ovn_controller

        '
    name: Implement the hybrid state for ovn_controller
    when: hybrid_ovn_controller.rc != 0
  - name: Get ovn remote setting
    register: ovn_remote
    shell: 'ovs-vsctl get open . external_ids:ovn-remote

      '
  - name: Set fact - OVN SB connection string
    set_fact:
      ovn_sb_conn_str: '{{ [enable_internal_tls | bool | ternary(''ssl'',''tcp''),
        ovn_dbs_vip | ipwrap, service_configs[''ovn::southbound::port'']] | join('':'')
        }}'
  - name: Set new ovn remote setting
    shell: 'ovs-vsctl set open . external_ids:ovn-remote="{{ ovn_sb_conn_str }}"

      '
    when: ovn_sb_conn_str not in ovn_remote.stdout
  - name: Update OVNIntegrationBridge protocols to OpenFlow13,OpenFlow15
    shell: ovs-vsctl set bridge {{ ovn_interaction_bridge }} protocols="OpenFlow13,OpenFlow15"
  name: Switch ovn-controller to hybrid state
  tags:
  - never
  - nova_hybrid_state
  vars:
    ovn_controller_image: registry.redhat.io/rhosp-rhel8/openstack-ovn-controller:16.2
    ovn_interaction_bridge: br-int
  when:
  - step|int == 0
  - ansible_facts['distribution'] == 'RedHat'
  - ansible_facts['distribution_major_version'] is version('7', '==')
- block:
  - become: true
    delegate_to: '{{ mysql_short_bootstrap_node_name }}'
    name: check flag file existence in destination host
    register: tripleo_transfer_flag_stat
    stat:
      path: /var/lib/tripleo/transfer-flags/var-lib-mysql
  - name: Set fact cluster_recreate
    set_fact:
      cluster_recreate: '{{ tripleo_transfer_flag_stat.stat.exists|bool }}'
  - async: 30
    name: Check pacemaker cluster running before upgrade
    pacemaker_cluster: state=online check_and_fail=true
    poll: 4
    tags: validation
    when: not cluster_recreate|bool
  name: upgrade step 0
  when: step|int == 0
- block:
  - name: set pacemaker upgrade node facts in a single-node environment
    set_fact:
      cacheable: false
      pacemaker_short_node_names_upgraded: '{{ pacemaker_short_node_names }}'
    when: groups['pacemaker'] | length <= 1
  - loop: '{{ pacemaker_short_node_names }}'
    name: set pacemaker upgrade node facts from the limit option
    set_fact:
      cacheable: false
      pacemaker_short_node_names_upgraded: '{{ pacemaker_short_node_names_upgraded|default([])
        + [item.split(''.'')[0]] }}'
    when:
    - groups['pacemaker'] | length > 1
    - item.split('.')[0] in ansible_limit.split(':')
  - fail:
      msg: 'You can''t upgrade pacemaker without staged upgrade. You need to use the
        limit option in order to do so.

        '
    when: pacemaker_short_node_names_upgraded is not defined or pacemaker_short_node_names_upgraded
      | length == 0
  - debug:
      msg: Prepare pacemaker upgrade for {{ pacemaker_short_node_names_upgraded }}
  - name: set pacemaker node ips fact from the names fact
    set_fact:
      cacheable: false
      pacemaker_node_ips_upgraded: '{{ dict(pacemaker_short_node_names|zip(pacemaker_node_ips))
        | dict2items | selectattr(''key'', ''in'', pacemaker_short_node_names_upgraded)
        | map(attribute=''value'') | list }}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the pacemaker short name to hiera data for the upgrade.
    vars:
      tripleo_upgrade_key: pacemaker_short_node_names_override
      tripleo_upgrade_value: '{{pacemaker_short_node_names_upgraded}}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the pacemaker ips to hiera data for the upgrade.
    vars:
      tripleo_upgrade_key: pacemaker_node_ips_override
      tripleo_upgrade_value: '{{pacemaker_node_ips_upgraded}}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: remove.yml
    loop:
    - pacemaker_short_node_names_override
    - pacemaker_node_ips_override
    name: remove the extra hiera data needed for the upgrade.
    vars:
      tripleo_upgrade_key: '{{item}}'
    when: pacemaker_short_node_names_upgraded | length == pacemaker_short_node_names
      | length
  name: Create hiera data to upgrade pacemaker in a stepwise manner.
  when:
  - step|int == 1
  - cluster_recreate|bool
- block:
  - name: Stop pacemaker cluster
    pacemaker_cluster: state=offline
    when: not cluster_recreate|bool
  name: upgrade step 2
  when: step|int == 2
- block:
  - name: Start pacemaker cluster
    pacemaker_cluster: state=online
    when: not cluster_recreate|bool
  name: upgrade step 4
  when: step|int == 4
- block:
  - failed_when: false
    name: Get rabbitmq image id currently used by pacemaker
    register: rabbitmq_image_current_res
    shell: pcs resource config rabbitmq-bundle | grep -Eo 'image=[^ ]+' | awk -F=
      '{print $2;}'
  - name: Image facts for rabbitmq
    set_fact:
      rabbitmq_image_current: '{{rabbitmq_image_current_res.stdout}}'
      rabbitmq_image_latest: cluster.common.tag/openstack-rabbitmq:pcmklatest
  - block:
    - import_role:
        name: tripleo-container-tag
      name: Temporarily tag the current rabbitmq image id with the upgraded image
        name
      vars:
        container_image: '{{rabbitmq_image_current}}'
        container_image_latest: '{{rabbitmq_image_latest}}'
        pull_image: false
      when:
      - rabbitmq_image_current != ''
      - rabbitmq_image_current != rabbitmq_image_latest
    name: Prepare the switch to new rabbitmq container image name in pacemaker
  - failed_when: false
    name: Check rabbitmq cluster resource status
    register: rabbitmq_pcs_res_result
    shell: pcs resource config rabbitmq-bundle
  - name: Set fact rabbitmq_pcs_res
    set_fact:
      rabbitmq_pcs_res: '{{rabbitmq_pcs_res_result.rc == 0}}'
  - name: set is_rpc_rabbitmq_bootstrap_node fact
    set_fact: is_rpc_rabbitmq_bootstrap_node={{oslo_messaging_rpc_short_bootstrap_node_name|lower
      == ansible_facts['hostname']|lower}}
  name: Prepare switch of rabbitmq image name
  when:
  - step|int == 0
- block:
  - name: Disable the rabbitmq cluster resource before container upgrade
    pacemaker_resource:
      resource: rabbitmq-bundle
      state: disable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
  - block:
    - command: cibadmin --query --xpath "//storage-mapping[@id='rabbitmq-log']"
      failed_when: false
      name: Check rabbitmq logging configuration in pacemaker
      register: rabbitmq_logs_moved
    - command: pcs resource bundle update rabbitmq-bundle storage-map add id=rabbitmq-log
        source-dir=/var/log/containers/rabbitmq target-dir=/var/log/rabbitmq options=rw
      name: Add a bind mount for logging in the rabbitmq bundle
      when: rabbitmq_logs_moved.rc == 6
    name: Move rabbitmq logging to /var/log/containers
  - command: pcs resource bundle update rabbitmq-bundle container image={{rabbitmq_image_latest}}
    name: Update the rabbitmq bundle to use the new container image name
  - name: Enable the rabbitmq cluster resource
    pacemaker_resource:
      resource: rabbitmq-bundle
      state: enable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
  name: Update rabbitmq-bundle pcs resource bundle for new container image
  when:
  - step|int == 1
  - is_rpc_rabbitmq_bootstrap_node|bool
  - rabbitmq_pcs_res|bool
  - rabbitmq_image_current != rabbitmq_image_latest
- block:
  - name: set oslo_messaging_rpc upgrade node facts in a single-node environment
    set_fact:
      cacheable: false
      oslo_messaging_rpc_node_names_upgraded: '{{ oslo_messaging_rpc_node_names }}'
      oslo_messaging_rpc_short_node_names_upgraded: '{{ oslo_messaging_rpc_short_node_names
        }}'
    when: groups['oslo_messaging_rpc'] | length <= 1
  - loop: '{{ oslo_messaging_rpc_node_names }}'
    name: set oslo_messaging_rpc upgrade node facts from the limit option
    set_fact:
      cacheable: false
      oslo_messaging_rpc_node_names_upgraded: '{{ oslo_messaging_rpc_node_names_upgraded|default([])
        + [item] }}'
      oslo_messaging_rpc_short_node_names_upgraded: '{{ oslo_messaging_rpc_short_node_names_upgraded|default([])
        + [item.split(''.'')[0]] }}'
    when:
    - groups['oslo_messaging_rpc'] | length > 1
    - item.split('.')[0] in ansible_limit.split(':')
  - fail:
      msg: 'You can''t upgrade oslo_messaging_rpc without staged upgrade.  You need
        to use the limit option in order to do so.

        '
    when: oslo_messaging_rpc_short_node_names_upgraded is not defined or oslo_messaging_rpc_short_node_names_upgraded
      | length == 0 or oslo_messaging_rpc_node_names_upgraded is not defined or oslo_messaging_rpc_node_names_upgraded
      | length == 0
  - debug:
      msg: Prepare oslo_messaging_rpc upgrade for {{ oslo_messaging_rpc_short_node_names_upgraded
        }}
  - include_role:
      name: tripleo-container-rm
    name: remove rabbitmq init container on upgrade-scaleup to force re-init
    vars:
      tripleo_containers_to_rm:
      - rabbitmq_wait_bundle
    when:
    - oslo_messaging_rpc_short_node_names_upgraded | length > 1
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the oslo_messaging_rpc short name to hiera data for the upgrade.
    vars:
      tripleo_upgrade_key: oslo_messaging_rpc_short_node_names_override
      tripleo_upgrade_value: '{{oslo_messaging_rpc_short_node_names_upgraded}}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the oslo_messaging_rpc long name to hiera data for the upgrade
    vars:
      tripleo_upgrade_key: oslo_messaging_rpc_node_names_override
      tripleo_upgrade_value: '{{oslo_messaging_rpc_node_names_upgraded}}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: remove.yml
    loop:
    - oslo_messaging_rpc_short_node_names_override
    - oslo_messaging_rpc_node_names_override
    name: remove the extra hiera data needed for the upgrade.
    vars:
      tripleo_upgrade_key: '{{item}}'
    when: oslo_messaging_rpc_short_node_names_upgraded | length == oslo_messaging_rpc_node_names
      | length
  name: Create hiera data to upgrade oslo messaging rpc in a stepwise manner.
  when:
  - step|int == 1
  - cluster_recreate|bool
- block:
  - name: Get container rabbitmq image
    set_fact:
      rabbitmq_image: registry.redhat.io/rhosp-rhel8/openstack-rabbitmq:16.2
      rabbitmq_image_latest: cluster.common.tag/openstack-rabbitmq:pcmklatest
  - command: '{{container_cli}} pull {{rabbitmq_image}}'
    delay: 3
    name: Pull latest rabbitmq images
    register: result
    retries: 3
    until: result.rc == 0
  - failed_when: false
    name: Get previous rabbitmq image id
    register: old_rabbitmq_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{rabbitmq_image_latest}}'
  - name: Get new rabbitmq image id
    register: new_rabbitmq_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{rabbitmq_image}}'
  - include_role:
      name: tripleo-container-tag
    name: Retag pcmklatest to latest rabbitmq image
    vars:
      container_image: '{{rabbitmq_image}}'
      container_image_latest: '{{rabbitmq_image_latest}}'
    when:
    - old_rabbitmq_image_id.stdout != new_rabbitmq_image_id.stdout
  name: Retag the pacemaker image if containerized
  when:
  - step|int == 3
- block:
  - args:
      executable: /bin/bash
      warn: false
    changed_when: _selinux_config_data.rc == 2
    failed_when: _selinux_config_data.rc not in [0,2]
    name: Ensure /var/lib/config-data context
    register: _selinux_config_data
    shell: "set -o pipefail\nif [[ -e /var/lib/config-data ]]; then\n  chcon -R -t\
      \ container_file_t /var/lib/config-data\n  exit 2\nfi"
  - lineinfile:
      dest: /etc/hosts
      line: '{{ undercloud_hosts_entries | join('''') }}'
      state: present
    name: Make sure the Undercloud hostname is included in /etc/hosts
    when:
    - undercloud_hosts_entries is defined
  - name: Set container_registry_insecure_registries fact.
    set_fact:
      container_registry_insecure_registries: []
  - include_role:
      name: tripleo-podman
      tasks_from: tripleo_podman_install.yml
    vars:
      tripleo_container_registry_insecure_registries: '{{ container_registry_insecure_registries
        }}'
  name: Run podman install
  when:
  - step|int == 1
- block:
  - name: Check if pcs is present
    register: pcs_stat
    stat:
      path: /usr/sbin/pcs
  - name: Stop pacemaker cluster before stopping all docker containers
    pacemaker_cluster: state=offline
    when: pcs_stat.stat.exists
  - command: /usr/sbin/pcs cluster destroy
    name: Destroy pacemaker cluster
    when: pcs_stat.stat.exists
  - include_role:
      name: tripleo-podman
      tasks_from: tripleo_docker_stop.yml
    name: Stop all services by stopping all docker containers
    tags:
    - never
    - system_upgrade
    - system_upgrade_prepare
  name: system_upgrade_prepare step 2
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  when:
  - step|int == 2
- block:
  - failed_when: false
    name: Get redis image id currently used by pacemaker
    register: redis_image_current_res
    shell: pcs resource config redis-bundle | grep -Eo 'image=[^ ]+' | awk -F= '{print
      $2;}'
  - name: Image facts for redis
    set_fact:
      redis_image_current: '{{redis_image_current_res.stdout}}'
      redis_image_latest: cluster.common.tag/openstack-redis:pcmklatest
  - import_role:
      name: tripleo-container-tag
    name: Temporarily tag the current redis image id with the upgraded image name
    vars:
      container_image: '{{redis_image_current}}'
      container_image_latest: '{{redis_image_latest}}'
      pull_image: false
    when:
    - redis_image_current != ''
    - redis_image_current != redis_image_latest
  - changed_when: false
    failed_when: false
    name: Check redis cluster resource status
    register: redis_pcs_res_result
    shell: pcs resource config redis-bundle
  - name: Set upgrade redis facts
    set_fact:
      is_redis_bootstrap_node: '{{redis_short_bootstrap_node_name|lower == ansible_facts[''hostname'']|lower}}'
      redis_pcs_res: '{{redis_pcs_res_result.rc == 0}}'
  name: Prepare switch of redis image name
  when:
  - step|int == 0
- block:
  - name: Disable the redis cluster resource before container upgrade
    pacemaker_resource:
      resource: redis-bundle
      state: disable
      wait_for_resource: true
    register: output
    retries: 5
    until: output.rc == 0
  - block:
    - command: cibadmin --query --xpath "//storage-mapping[@id='redis-log' and @source-dir='/var/log/containers/redis']"
      failed_when: false
      name: Check redis logging configuration in pacemaker
      register: redis_logs_moved
    - block:
      - command: pcs resource bundle update redis-bundle storage-map remove redis-log
        name: Remove old bind mount for logging in the redis bundle
      - command: pcs resource bundle update redis-bundle storage-map add id=redis-log
          source-dir=/var/log/containers/redis target-dir=/var/log/redis options=rw
        name: Add a bind mount for logging in the redis bundle
      name: Change redis logging configuration in pacemaker
      when: redis_logs_moved.rc == 6
    name: Move redis logging to /var/log/containers
  - command: pcs resource bundle update redis-bundle container image={{redis_image_latest}}
    name: Update the redis bundle to use the new container image name
  name: Update redis-bundle pcs resource bundle for new container image
  when:
  - step|int == 1
  - is_redis_bootstrap_node|bool
  - redis_pcs_res|bool
  - redis_image_current != redis_image_latest
- block:
  - name: set redis upgrade node facts in a single-node environment
    set_fact:
      cacheable: false
      redis_short_node_names_upgraded: '{{ redis_short_node_names }}'
    when: groups['redis'] | length <= 1
  - loop: '{{ redis_short_node_names }}'
    name: set redis upgrade node facts from the limit option
    set_fact:
      cacheable: false
      redis_short_node_names_upgraded: '{{ redis_short_node_names_upgraded|default([])
        + [item.split(''.'')[0]] }}'
    when:
    - groups['redis'] | length > 1
    - item.split('.')[0] in ansible_limit.split(':')
  - fail:
      msg: 'You can''t upgrade redis without staged upgrade. You need to use the limit
        option in order to do so.

        '
    when: redis_short_node_names_upgraded is not defined or redis_short_node_names_upgraded
      | length == 0
  - debug:
      msg: Prepare redis upgrade for {{ redis_short_node_names_upgraded }}
  - include_role:
      name: tripleo-container-rm
    name: remove redis init container on upgrade-scaleup to force re-init
    vars:
      tripleo_containers_to_rm:
      - redis_init_bundle
    when:
    - redis_short_node_names_upgraded | length > 1
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: set.yml
    name: add the redis short name to hiera data for the upgrade.
    vars:
      tripleo_upgrade_key: redis_short_node_names_override
      tripleo_upgrade_value: '{{redis_short_node_names_upgraded}}'
  - include_role:
      name: tripleo-upgrade-hiera
      tasks_from: remove.yml
    name: remove the extra hiera data needed for the upgrade.
    vars:
      tripleo_upgrade_key: redis_short_node_names_override
    when: redis_short_node_names_upgraded | length == redis_short_node_names | length
  name: Create hiera data to upgrade redis in a stepwise manner.
  when:
  - step|int == 1
  - cluster_recreate|bool
- block:
  - name: Get container redis image
    set_fact:
      redis_image: registry.redhat.io/rhosp-rhel8/openstack-redis:16.2
      redis_image_latest: cluster.common.tag/openstack-redis:pcmklatest
  - command: '{{container_cli}} pull {{redis_image}}'
    delay: 3
    name: Pull latest redis images
    register: result
    retries: 3
    until: result.rc == 0
  - failed_when: false
    name: Get previous redis image id
    register: old_redis_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{redis_image_latest}}'
  - name: Get new redis image id
    register: new_redis_image_id
    shell: '{{container_cli}} inspect --format ''{{''{{''}}.Id{{''}}''}}'' {{redis_image}}'
  - include_role:
      name: tripleo-container-tag
    name: Retag pcmklatest to latest redis image
    vars:
      container_image: '{{redis_image}}'
      container_image_latest: '{{redis_image_latest}}'
    when:
    - old_redis_image_id.stdout != new_redis_image_id.stdout
  name: Retag the pacemaker image if containerized
  when:
  - step|int == 3
- block:
  - command: systemctl is-enabled --quiet snmpd
    failed_when: false
    name: Check if snmpd is enabled
    register: snmpd_enabled_result
  - name: Set fact snmpd_enabled
    set_fact:
      snmpd_enabled: '{{ snmpd_enabled_result.rc == 0 }}'
  when: step|int == 0
- name: Stop snmp service
  service: name=snmpd state=stopped
  when:
  - step|int == 1
  - snmpd_enabled|bool
- block:
  - args:
      creates: /etc/sysconfig/ip6tables.n-o-upgrade
    name: blank ipv6 rule before activating ipv6 firewall.
    shell: cat /etc/sysconfig/ip6tables > /etc/sysconfig/ip6tables.n-o-upgrade; cat</dev/null>/etc/sysconfig/ip6tables
  - name: cleanup unmanaged rules pushed by iptables-services
    shell: "iptables -C INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT &>/dev/null\
      \ && \\\n  iptables -D INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\n\
      iptables -C INPUT -p icmp -j ACCEPT &>/dev/null && \\\n  iptables -D INPUT -p\
      \ icmp -j ACCEPT\niptables -C INPUT -i lo -j ACCEPT &>/dev/null && \\\n  iptables\
      \ -D INPUT -i lo -j ACCEPT\niptables -C INPUT -p tcp -m state --state NEW -m\
      \ tcp --dport 22 -j ACCEPT &>/dev/null && \\\n  iptables -D INPUT -p tcp -m\
      \ state --state NEW -m tcp --dport 22 -j ACCEPT\niptables -C INPUT -j REJECT\
      \ --reject-with icmp-host-prohibited &>/dev/null && \\\n  iptables -D INPUT\
      \ -j REJECT --reject-with icmp-host-prohibited\niptables -C FORWARD -j REJECT\
      \ --reject-with icmp-host-prohibited &>/dev/null && \\\n  iptables -D FORWARD\
      \ -j REJECT --reject-with icmp-host-prohibited\n\nsed -i '/^-A INPUT -m state\
      \ --state RELATED,ESTABLISHED -j ACCEPT$/d' /etc/sysconfig/iptables\nsed -i\
      \ '/^-A INPUT -p icmp -j ACCEPT$/d' /etc/sysconfig/iptables\nsed -i '/^-A INPUT\
      \ -i lo -j ACCEPT$/d' /etc/sysconfig/iptables\nsed -i '/^-A INPUT -p tcp -m\
      \ state --state NEW -m tcp --dport 22 -j ACCEPT$/d' /etc/sysconfig/iptables\n\
      sed -i '/^-A INPUT -j REJECT --reject-with icmp-host-prohibited$/d' /etc/sysconfig/iptables\n\
      sed -i '/^-A FORWARD -j REJECT --reject-with icmp-host-prohibited$/d' /etc/sysconfig/iptables\n\
      \nip6tables -C INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT &>/dev/null\
      \ && \\\n  ip6tables -D INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\n\
      ip6tables -C INPUT -p ipv6-icmp -j ACCEPT &>/dev/null && \\\n  ip6tables -D\
      \ INPUT -p ipv6-icmp -j ACCEPT\nip6tables -C INPUT -i lo -j ACCEPT &>/dev/null\
      \ && \\\n  ip6tables -D INPUT -i lo -j ACCEPT\nip6tables -C INPUT -p tcp -m\
      \ state --state NEW -m tcp --dport 22 -j ACCEPT &>/dev/null && \\\n  ip6tables\
      \ -D INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT\nip6tables\
      \ -C INPUT -d fe80::/64 -p udp -m udp --dport 546 -m state --state NEW -j ACCEPT\
      \ &>/dev/null && \\\n  ip6tables -D INPUT -d fe80::/64 -p udp -m udp --dport\
      \ 546 -m state --state NEW -j ACCEPT\nip6tables -C INPUT -j REJECT --reject-with\
      \ icmp6-adm-prohibited &>/dev/null && \\\n  ip6tables -D INPUT -j REJECT --reject-with\
      \ icmp6-adm-prohibited\nip6tables -C FORWARD -j REJECT --reject-with icmp6-adm-prohibited\
      \ &>/dev/null && \\\n  ip6tables -D FORWARD -j REJECT --reject-with icmp6-adm-prohibited\n\
      \nsed -i '/^-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT$/d' /etc/sysconfig/ip6tables\n\
      sed -i '/^-A INPUT -p ipv6-icmp -j ACCEPT$/d' /etc/sysconfig/ip6tables\nsed\
      \ -i '/^-A INPUT -i lo -j ACCEPT$/d' /etc/sysconfig/ip6tables\nsed -i '/^-A\
      \ INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT$/d' /etc/sysconfig/ip6tables\n\
      sed -i '/^-A INPUT -d fe80::\\/64 -p udp -m udp --dport 546 -m state --state\
      \ NEW -j ACCEPT$/d' /etc/sysconfig/ip6tables\nsed -i '/^-A INPUT -j REJECT --reject-with\
      \ icmp6-adm-prohibited$/d' /etc/sysconfig/ip6tables\nsed -i '/^-A FORWARD -j\
      \ REJECT --reject-with icmp6-adm-prohibited$/d' /etc/sysconfig/ip6tables"
  when: step|int == 3
- name: Gather missing facts
  setup:
    gather_subset: distribution
  tags:
  - always
  when: ansible_facts['distribution'] is not defined or ansible_facts['distribution_major_version']
    is not defined
- name: Set leapp facts
  set_fact:
    upgrade_leapp_command_options: ''
    upgrade_leapp_debug: true
    upgrade_leapp_devel_skip: ''
    upgrade_leapp_enabled: "{{ _upgradeLeappEnabled | bool and\n   ansible_facts['distribution']\
      \ == 'RedHat' and\n   ansible_facts['distribution_major_version'] is version('7',\
      \ '==') }}"
    upgrade_leapp_post_reboot_delay: 120
    upgrade_leapp_reboot_timeout: 3600
  tags:
  - always
  vars:
    _upgradeLeappEnabled: false
- block:
  - ignore_errors: true
    name: Hack around broken ceph-common rpm removing /etc/ceph /var/lib/ceph
    shell: 'rpm -e --nodeps --noscripts ceph-common

      '
  - name: remove all OpenStack packages
    shell: yum -y remove *el7ost* galera* xinetd* haproxy* httpd kernel-devel mysql*
      pacemaker* python-jsonpointer qemu-kvm-common-rhev qemu-img-rhev rabbit* redis*
      -- -*openvswitch* -python-docker -python-PyMySQL -python-pysocks -python2-asn1crypto
      -python2-babel -python2-cffi -python2-cryptography -python2-dateutil -python2-idna
      -python2-ipaddress -python2-jinja2 -python2-jsonpatch -python2-markupsafe -python2-pyOpenSSL
      -python2-requests -python2-six -python2-urllib3 -python2-chardet
  - name: Run LeappRepoInitCommand
    shell: '#!/bin/bash


      '
  - name: Check if system was booted via EFI
    register: efi
    stat:
      path: /sys/firmware/efi
  - failed_when: false
    name: Check if efi partition is present in /etc/fstab
    register: efi_fstab
    shell: 'grep efi /etc/fstab

      '
  - failed_when: false
    name: Find out the UUID of UEFI device
    register: efi_dev
    shell: 'blkid -s UUID -o value "$(blkid -t TYPE=vfat | grep -i efi | cut -d '':''
      -f1)"

      '
  - failed_when: false
    name: Check if red is in efibootmgr
    register: efi_broken
    shell: 'efibootmgr | grep "red$"

      '
  - block:
    - copy:
        dest: /tmp/workaround_1925078_redhat/
        remote_src: true
        src: /boot/efi/EFI/redhat/
      name: Copy /boot/efi/EFI/redhat to /tmp
    - lineinfile:
        dest: /etc/fstab
        line: UUID={{ efi_dev.stdout }} /boot/efi vfat umask=0077 0 1
      name: Insert /etc/fstab record
    - command: mount /boot/efi
      name: Mount the /boot/efi
    - copy:
        dest: /boot/efi/EFI/redhat/
        remote_src: true
        src: /tmp/workaround_1925078_redhat/
      name: Copy /tmp/redhat to /boot/efi/EFI/redhat
    - name: Create boot record
      shell: 'DEVICE_PATH="$(blkid -t TYPE=vfat | grep -i efi | cut -d '':'' -f1)"

        DEVICE="$(lsblk -no pkname $DEVICE_PATH)"

        PARTITION="$(echo $DEVICE_PATH | awk ''{print $NF}'' FS=/$DEVICE)"

        efibootmgr -c -L ''Red Hat Enterprise Linux'' -d $(echo $DEVICE_PATH | sed
        s/$PARTITION\$//) -p $PARTITION -l ''\EFI\redhat\shimx64.efi''

        '
    - command: grub2-mkconfig -o /boot/efi/EFI/redhat/grub.cfg
      name: Create grub config file
    - command: rmmod btrfs
      failed_when: false
      name: Remove btrfs module in case fuse just loaded it
    - name: Set workaround_1925078_fired
      set_fact:
        workaround_1925078_fired: true
    when:
    - efi_fstab.rc is defined
    - efi_dev.rc is defined
    - efi_broken.rc is defined
    - efi.stat.exists|bool
    - efi_fstab.rc == 1
    - efi_dev.rc == 0
    - efi_broken.rc == 0
  - name: install leapp
    package:
      name: leapp
      state: latest
  - delegate_to: undercloud
    find:
      paths: /etc/leapp/files
      patterns: '*'
    name: Retrieve files in /etc/leapp/files
    register: uc_leapp_files
  - delegate_to: undercloud
    fetch:
      dest: '{{ playbook_dir }}'
      src: '{{ item.path }}'
    loop: '{{ uc_leapp_files.files }}'
    name: Fetch the Leapp data from undercloud
  - copy:
      dest: '{{ item.path }}'
      src: '{{ playbook_dir }}/{{ inventory_hostname }}/{{ item.path }}'
    loop: '{{ uc_leapp_files.files }}'
    name: Copy the Leapp data from undercloud
  - name: Run LeappInitCommand
    shell: '#!/bin/bash


      '
  - file:
      path: /etc/modules-load.d/nf_conntrack_proto_sctp.conf
      state: absent
    name: Remove obsolete nf_conntrack_proto_sctp from /etc/modules-load.d/
  - lineinfile:
      line: '{{ item }}'
      path: /etc/leapp/transaction/to_remove
    loop: '{{ pkg_to_remove }}'
    name: add packages into Leapp's to_remove file
    vars:
      pkg_to_remove: []
  - lineinfile:
      line: '{{ item }}'
      path: /etc/leapp/transaction/to_install
    loop: '{{ pkg_to_install }}'
    name: add packages into Leapp's to_install file
    vars:
      pkg_to_install: []
  - name: check sshd_config file
    register: sshd_config_result
    stat:
      path: /etc/ssh/sshd_config
  - lineinfile:
      line: PermitRootLogin without-password
      path: /etc/ssh/sshd_config
      regexp: ^(# *)?PermitRootLogin
    name: add PermitRootLogin option for leapp
  name: system_upgrade_prepare step 3
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  when:
  - step|int == 3
  - upgrade_leapp_enabled
- block:
  - ignore_errors: true
    mount: path=/var/lib/glance/images state=absent
    name: unmount and remove nfs glance entry
  - ignore_errors: true
    mount: path="{{glance_node_staging_uri[7:]}}" state=absent
    name: unmount and remove nfs glance staging entry
    vars:
      glance_node_staging_uri: file:///var/lib/glance/staging
  - ignore_errors: true
    mount: path=/var/lib/nova/instances state=absent
    name: unmount and remove nfs nova entry
  - lineinfile:
      path: /usr/share/leapp-repository/repositories/system_upgrade/el7toel8/actors/kernel/checkkerneldrivers/files/removed_drivers.txt
      regexp: '{{ item }}'
      state: absent
    loop: '{{ modules_to_unload }}'
    name: Remove kernel drivers from Leapp removed_drivers.txt before running Leapp
    vars:
      modules_to_unload:
      - floppy
      - pata_acpi
  - name: set leapp options
    shell: 'leapp answer --section remove_pam_pkcs11_module_check.confirm=True --add

      '
  - name: run leapp upgrade (download packages)
    shell: '{% if upgrade_leapp_devel_skip|default(false) %}{{ upgrade_leapp_devel_skip
      }}{% endif %} leapp upgrade {% if upgrade_leapp_debug|default(true) %}--debug{%
      endif %} {% if upgrade_leapp_command_options|default(false) %}{{ upgrade_leapp_command_options
      }}{% endif %}

      '
  name: system_upgrade_prepare step 4
  tags:
  - never
  - system_upgrade
  - system_upgrade_prepare
  when:
  - step|int == 4
  - upgrade_leapp_enabled
- block:
  - block:
    - name: null
      shell: 'NEXT_BOOT="$(efibootmgr -v | grep \\redhat | awk -F''[ t*]'' ''{print
        $2}'')"

        efibootmgr -n $NEXT_BOOT

        '
    - name: Stat /boot/grub2/grubenv
      register: grubenv
      stat:
        path: /boot/grub2/grubenv
    - copy:
        dest: /boot/efi/EFI/redhat/grubenv
        remote_src: true
        src: /boot/grub2/grubenv
      name: Copy /boot/grub2/grubenv to /boot/efi/EFI/redhat/grubenv
      when: grubenv.stat.islnk is defined and grubenv.stat.islnk == False
    name: Reset boot order if WA#1925078 fired and fix grubenv
    when:
    - workaround_1925078_fired is defined
    - workaround_1925078_fired|bool
  - name: reboot to perform the upgrade
    reboot:
      post_reboot_delay: '{{ upgrade_leapp_post_reboot_delay }}'
      reboot_timeout: '{{upgrade_leapp_reboot_timeout}}'
      test_command: systemctl is-system-running | grep -e running -e degraded
  - name: Set the python to python3
    shell: alternatives --set python /usr/bin/python3
    vars:
      ansible_python_interpreter: /usr/bin/python3
  name: system_upgrade_run step 4
  tags:
  - never
  - system_upgrade
  - system_upgrade_run
  - system_upgrade_reboot
  when:
  - step|int == 4
  - upgrade_leapp_enabled
- block:
  - name: Run UpgradeInitCommand
    shell: '#!/bin/bash


      '
  - name: Run UpgradeInitCommonCommand
    shell: '#!/bin/bash


      '
  - dnf:
      name: '@{{ item.module }}:{{ item.stream }}/{{ item.profile|default(''common'')
        }}'
      state: present
    loop: '{{ dnf_module_list|list }}'
    name: Ensure DNF modules have the right stream
    vars:
      dnf_module_list: []
    when:
    - ansible_facts['distribution_major_version'] is version('8', '>=')
    - dnf_module_list|length > 0
  - delay: 10
    name: Ensure EL modules are in proper state
    register: _dnf_distro_sync
    retries: 5
    shell: dnf -y distro-sync
    until: _dnf_distro_sync is success
    when: ansible_facts['distribution_major_version'] == '8'
  - name: Clean up Python 2 packages
    package:
      name: python2-*
      state: absent
    when: ansible_facts['distribution_major_version'] == '8'
  - name: Ensure TripleO prerequisite packages are installed
    package:
      name:
      - jq
      - lvm2
      - net-snmp
      - openstack-selinux
      - os-net-config
      - puppet-tripleo
      - python3-heat-agent*
      - rsync
      state: present
    when: ansible_facts['distribution_major_version'] is version('8', '==')
  name: Package and repo update tasks
  when: step|int == 0
- name: Special treatment for OpenvSwitch
  register: ovs_upgrade
  tripleo_ovs_upgrade: null
  when:
  - step|int == 2
- name: Always ensure the openvswitch service is enabled and running after upgrades
  service:
    enabled: true
    name: openvswitch
    state: started
  when:
  - step|int == 2
  - ovs_upgrade.changed|bool
- name: Install libibverbs (https://bugs.launchpad.net/tripleo/+bug/1817743)
  package:
    name: libibverbs
    state: installed
  when: step|int == 2
- name: Check for os-net-config upgrade
  register: os_net_config_need_upgrade
  shell: yum check-upgrade | awk '/os-net-config/{print}'
  when: step|int == 3
- failed_when: false
  name: Check that os-net-config has configuration
  register: os_net_config_has_config
  shell: test -s /etc/os-net-config/config.json
  when: step|int == 3
- block:
  - name: Upgrade os-net-config
    package: name=os-net-config state=latest
  - changed_when: os_net_config_upgrade.rc == 2
    command: os-net-config --no-activate -c /etc/os-net-config/config.json -v --detailed-exit-codes
    failed_when: os_net_config_upgrade.rc not in [0,2]
    name: take new os-net-config parameters into account now
    register: os_net_config_upgrade
  when:
  - step|int == 3
  - os_net_config_need_upgrade.stdout
  - os_net_config_has_config.rc == 0
- name: Set boolean skip_package_update
  set_fact:
    skip_package_update: false
- name: Update all packages
  when:
  - step|int == 3
  - not skip_package_update|bool
  yum:
    exclude: ansible
    name: '*'
    state: latest
